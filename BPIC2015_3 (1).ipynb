{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "16SqPNMLnSrk",
    "outputId": "bd844960-de02-47d8-fe85-92087d521efa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dias\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Resource</th>\n",
       "      <th>Complete Timestamp</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Variant index</th>\n",
       "      <th>(case) IDofConceptCase</th>\n",
       "      <th>(case) Includes_subCases</th>\n",
       "      <th>(case) Responsible_actor</th>\n",
       "      <th>(case) SUMleges</th>\n",
       "      <th>...</th>\n",
       "      <th>activityNameNL</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>dateFinished</th>\n",
       "      <th>dateStop</th>\n",
       "      <th>dueDate</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>monitoringResource</th>\n",
       "      <th>planned</th>\n",
       "      <th>question</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3004646</td>\n",
       "      <td>register submission date request</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-04 07:00:00</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>registratie datum binnenkomst aanvraag</td>\n",
       "      <td>01_HOOFD_010</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-11T12:00:06+02:00</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-09T12:00:06+02:00</td>\n",
       "      <td>4-10-2010 0:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3004646</td>\n",
       "      <td>enter senddate acknowledgement</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-06 07:00:00</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>invoeren verzenddatum ontvangstbevestiging</td>\n",
       "      <td>01_HOOFD_030_2</td>\n",
       "      <td>2010-10-25 14:38:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-27T14:29:12+02:00</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:29:12+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3004646</td>\n",
       "      <td>phase application received</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:28:53</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>fase aanvraag ontvangen</td>\n",
       "      <td>01_HOOFD_015</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3004646</td>\n",
       "      <td>reception through OLO</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:29:03</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ontvangst via OLO</td>\n",
       "      <td>01_HOOFD_020</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-28T14:28:53+02:00</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:28:53+02:00</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3004646</td>\n",
       "      <td>send confirmation receipt</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:29:12</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>versturen ontvangstbevestiging</td>\n",
       "      <td>01_HOOFD_030_1</td>\n",
       "      <td>2010-10-25 14:38:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-27T14:29:03+02:00</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:29:03+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case ID                          Activity  Resource   Complete Timestamp  \\\n",
       "0  3004646  register submission date request    560922  2010-10-04 07:00:00   \n",
       "1  3004646    enter senddate acknowledgement    560922  2010-10-06 07:00:00   \n",
       "2  3004646        phase application received    560922  2010-10-25 21:28:53   \n",
       "3  3004646             reception through OLO    560922  2010-10-25 21:29:03   \n",
       "4  3004646         send confirmation receipt    560922  2010-10-25 21:29:12   \n",
       "\n",
       "      Variant  Variant index  (case) IDofConceptCase (case) Includes_subCases  \\\n",
       "0  Variant 17             17                     NaN                        N   \n",
       "1  Variant 17             17                     NaN                        N   \n",
       "2  Variant 17             17                     NaN                        N   \n",
       "3  Variant 17             17                     NaN                        N   \n",
       "4  Variant 17             17                     NaN                        N   \n",
       "\n",
       "   (case) Responsible_actor  (case) SUMleges  ...  \\\n",
       "0                    560922              NaN  ...   \n",
       "1                    560922              NaN  ...   \n",
       "2                    560922              NaN  ...   \n",
       "3                    560922              NaN  ...   \n",
       "4                    560922              NaN  ...   \n",
       "\n",
       "                               activityNameNL    concept:name  \\\n",
       "0      registratie datum binnenkomst aanvraag    01_HOOFD_010   \n",
       "1  invoeren verzenddatum ontvangstbevestiging  01_HOOFD_030_2   \n",
       "2                     fase aanvraag ontvangen    01_HOOFD_015   \n",
       "3                           ontvangst via OLO    01_HOOFD_020   \n",
       "4              versturen ontvangstbevestiging  01_HOOFD_030_1   \n",
       "\n",
       "          dateFinished  dateStop                    dueDate  \\\n",
       "0  2010-10-25 14:38:39       NaN  2010-10-11T12:00:06+02:00   \n",
       "1  2010-10-25 14:38:38       NaN  2010-10-27T14:29:12+02:00   \n",
       "2  2010-10-25 14:38:39       NaN                        NaN   \n",
       "3  2010-10-25 14:38:39       NaN  2010-10-28T14:28:53+02:00   \n",
       "4  2010-10-25 14:38:38       NaN  2010-10-27T14:29:03+02:00   \n",
       "\n",
       "  lifecycle:transition  monitoringResource                    planned  \\\n",
       "0             complete              560922  2010-10-09T12:00:06+02:00   \n",
       "1             complete              560922  2010-10-26T14:29:12+02:00   \n",
       "2             complete              560922                        NaN   \n",
       "3             complete              560922  2010-10-26T14:28:53+02:00   \n",
       "4             complete              560922  2010-10-26T14:29:03+02:00   \n",
       "\n",
       "            question Label  \n",
       "0  4-10-2010 0:00:00     1  \n",
       "1              EMPTY     1  \n",
       "2              EMPTY     1  \n",
       "3              False     1  \n",
       "4              EMPTY     1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import an event log as Dataframe\n",
    "\n",
    "file = pd.read_csv(r'C:\\Users\\Dias\\Desktop\\data\\dataset\\BPIC15_3prep.csv')\n",
    "raw_df = pd.DataFrame(file)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WjBs2QNcnSrq"
   },
   "outputs": [],
   "source": [
    "#df.to_csv(r'C:\\Users\\Dias\\Desktop\\data\\dataset\\BPIC15_1_dur.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "BrDhNJ2DnSrr",
    "outputId": "38e5dbed-2ac0-4544-ea07-187c3a3296da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Resource</th>\n",
       "      <th>Complete Timestamp</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Variant index</th>\n",
       "      <th>(case) IDofConceptCase</th>\n",
       "      <th>(case) Includes_subCases</th>\n",
       "      <th>(case) Responsible_actor</th>\n",
       "      <th>(case) SUMleges</th>\n",
       "      <th>...</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>dateFinished</th>\n",
       "      <th>dateStop</th>\n",
       "      <th>dueDate</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>monitoringResource</th>\n",
       "      <th>planned</th>\n",
       "      <th>question</th>\n",
       "      <th>Label</th>\n",
       "      <th>Accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3004646</td>\n",
       "      <td>register submission date request</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-04 07:00:00</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_010</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-11T12:00:06+02:00</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-09T12:00:06+02:00</td>\n",
       "      <td>4-10-2010 0:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3004646</td>\n",
       "      <td>enter senddate acknowledgement</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-06 07:00:00</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_030_2</td>\n",
       "      <td>2010-10-25 14:38:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-27T14:29:12+02:00</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:29:12+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3004646</td>\n",
       "      <td>phase application received</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:28:53</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_015</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3004646</td>\n",
       "      <td>reception through OLO</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:29:03</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_020</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-28T14:28:53+02:00</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:28:53+02:00</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3004646</td>\n",
       "      <td>send confirmation receipt</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:29:12</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_030_1</td>\n",
       "      <td>2010-10-25 14:38:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-27T14:29:03+02:00</td>\n",
       "      <td>complete</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:29:03+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59676</th>\n",
       "      <td>8484936</td>\n",
       "      <td>OLO messaging active</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 08:00:00</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_011</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:24:13+01:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59677</th>\n",
       "      <td>8484936</td>\n",
       "      <td>send confirmation receipt</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 08:00:00</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_020</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:24:13+01:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59678</th>\n",
       "      <td>8484936</td>\n",
       "      <td>phase application received</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 08:00:00</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_015</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:24:13+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59679</th>\n",
       "      <td>8484936</td>\n",
       "      <td>send confirmation receipt</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 08:00:00</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_030_1</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:24:18+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59680</th>\n",
       "      <td>8484936</td>\n",
       "      <td>enter senddate acknowledgement</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 23:28:08</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>01_HOOFD_030_2</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complete</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:28:08+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59681 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case ID                          Activity  Resource  \\\n",
       "0      3004646  register submission date request    560922   \n",
       "1      3004646    enter senddate acknowledgement    560922   \n",
       "2      3004646        phase application received    560922   \n",
       "3      3004646             reception through OLO    560922   \n",
       "4      3004646         send confirmation receipt    560922   \n",
       "...        ...                               ...       ...   \n",
       "59676  8484936              OLO messaging active    560749   \n",
       "59677  8484936         send confirmation receipt    560749   \n",
       "59678  8484936        phase application received    560749   \n",
       "59679  8484936         send confirmation receipt    560749   \n",
       "59680  8484936    enter senddate acknowledgement    560749   \n",
       "\n",
       "        Complete Timestamp     Variant  Variant index  (case) IDofConceptCase  \\\n",
       "0      2010-10-04 07:00:00  Variant 17             17                     NaN   \n",
       "1      2010-10-06 07:00:00  Variant 17             17                     NaN   \n",
       "2      2010-10-25 21:28:53  Variant 17             17                     NaN   \n",
       "3      2010-10-25 21:29:03  Variant 17             17                     NaN   \n",
       "4      2010-10-25 21:29:12  Variant 17             17                     NaN   \n",
       "...                    ...         ...            ...                     ...   \n",
       "59676  2015-03-04 08:00:00   Variant 3              3                     NaN   \n",
       "59677  2015-03-04 08:00:00   Variant 3              3                     NaN   \n",
       "59678  2015-03-04 08:00:00   Variant 3              3                     NaN   \n",
       "59679  2015-03-04 08:00:00   Variant 3              3                     NaN   \n",
       "59680  2015-03-04 23:28:08   Variant 3              3                     NaN   \n",
       "\n",
       "      (case) Includes_subCases  (case) Responsible_actor  (case) SUMleges  \\\n",
       "0                            N                    560922              NaN   \n",
       "1                            N                    560922              NaN   \n",
       "2                            N                    560922              NaN   \n",
       "3                            N                    560922              NaN   \n",
       "4                            N                    560922              NaN   \n",
       "...                        ...                       ...              ...   \n",
       "59676                     None                    560696              NaN   \n",
       "59677                     None                    560696              NaN   \n",
       "59678                     None                    560696              NaN   \n",
       "59679                     None                    560696              NaN   \n",
       "59680                     None                    560696              NaN   \n",
       "\n",
       "       ...    concept:name         dateFinished  dateStop  \\\n",
       "0      ...    01_HOOFD_010  2010-10-25 14:38:39       NaN   \n",
       "1      ...  01_HOOFD_030_2  2010-10-25 14:38:38       NaN   \n",
       "2      ...    01_HOOFD_015  2010-10-25 14:38:39       NaN   \n",
       "3      ...    01_HOOFD_020  2010-10-25 14:38:39       NaN   \n",
       "4      ...  01_HOOFD_030_1  2010-10-25 14:38:38       NaN   \n",
       "...    ...             ...                  ...       ...   \n",
       "59676  ...    01_HOOFD_011  2015-03-04 00:00:00       NaN   \n",
       "59677  ...    01_HOOFD_020  2015-03-04 00:00:00       NaN   \n",
       "59678  ...    01_HOOFD_015  2015-03-04 00:00:00       NaN   \n",
       "59679  ...  01_HOOFD_030_1  2015-03-04 00:00:00       NaN   \n",
       "59680  ...  01_HOOFD_030_2  2015-03-04 00:00:00       NaN   \n",
       "\n",
       "                         dueDate lifecycle:transition monitoringResource  \\\n",
       "0      2010-10-11T12:00:06+02:00             complete             560922   \n",
       "1      2010-10-27T14:29:12+02:00             complete             560922   \n",
       "2                            NaN             complete             560922   \n",
       "3      2010-10-28T14:28:53+02:00             complete             560922   \n",
       "4      2010-10-27T14:29:03+02:00             complete             560922   \n",
       "...                          ...                  ...                ...   \n",
       "59676                        NaN             complete             560696   \n",
       "59677                        NaN             complete             560696   \n",
       "59678                        NaN             complete             560696   \n",
       "59679                        NaN             complete             560696   \n",
       "59680                        NaN             complete             560696   \n",
       "\n",
       "                         planned           question Label Accepted  \n",
       "0      2010-10-09T12:00:06+02:00  4-10-2010 0:00:00     1        1  \n",
       "1      2010-10-26T14:29:12+02:00              EMPTY     1        1  \n",
       "2                            NaN              EMPTY     1        1  \n",
       "3      2010-10-26T14:28:53+02:00              False     1        1  \n",
       "4      2010-10-26T14:29:03+02:00              EMPTY     1        1  \n",
       "...                          ...                ...   ...      ...  \n",
       "59676  2015-03-05T15:24:13+01:00              False     0        1  \n",
       "59677  2015-03-05T15:24:13+01:00               True     0        1  \n",
       "59678  2015-03-05T15:24:13+01:00              EMPTY     0        1  \n",
       "59679  2015-03-05T15:24:18+01:00              EMPTY     0        1  \n",
       "59680  2015-03-05T15:28:08+01:00              EMPTY     0        1  \n",
       "\n",
       "[59681 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Labeling\n",
    "\n",
    "label = []\n",
    "for case, group in raw_df.groupby('Case ID'):\n",
    "    if 'send confirmation receipt' in group['Activity'].tolist():\n",
    "        for i in range(len(group)):\n",
    "            label.append(1)\n",
    "    else:\n",
    "        for i in range(len(group)):\n",
    "            label.append(0)\n",
    "            \n",
    "label_df = pd.DataFrame(label, columns = ['Accepted'])\n",
    "raw_df = pd.concat([raw_df, label_df], axis=1)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "3l0IIUn6nSrs",
    "outputId": "e9c42af7-053c-4612-c6fe-833a133ccb8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Resource</th>\n",
       "      <th>Complete Timestamp</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Variant index</th>\n",
       "      <th>(case) IDofConceptCase</th>\n",
       "      <th>(case) Includes_subCases</th>\n",
       "      <th>(case) Responsible_actor</th>\n",
       "      <th>(case) SUMleges</th>\n",
       "      <th>...</th>\n",
       "      <th>activityNameNL</th>\n",
       "      <th>dateFinished</th>\n",
       "      <th>dateStop</th>\n",
       "      <th>dueDate</th>\n",
       "      <th>monitoringResource</th>\n",
       "      <th>planned</th>\n",
       "      <th>question</th>\n",
       "      <th>Label</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3004646</td>\n",
       "      <td>register submission date request</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-04 07:00:00</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>registratie datum binnenkomst aanvraag</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-11T12:00:06+02:00</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-09T12:00:06+02:00</td>\n",
       "      <td>4-10-2010 0:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3004646</td>\n",
       "      <td>enter senddate acknowledgement</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-06 07:00:00</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>invoeren verzenddatum ontvangstbevestiging</td>\n",
       "      <td>2010-10-25 14:38:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-27T14:29:12+02:00</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:29:12+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3004646</td>\n",
       "      <td>phase application received</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:28:53</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>fase aanvraag ontvangen</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>470.481389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3004646</td>\n",
       "      <td>reception through OLO</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:29:03</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ontvangst via OLO</td>\n",
       "      <td>2010-10-25 14:38:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-28T14:28:53+02:00</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:28:53+02:00</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3004646</td>\n",
       "      <td>send confirmation receipt</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-25 21:29:12</td>\n",
       "      <td>Variant 17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>versturen ontvangstbevestiging</td>\n",
       "      <td>2010-10-25 14:38:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-27T14:29:03+02:00</td>\n",
       "      <td>560922</td>\n",
       "      <td>2010-10-26T14:29:03+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59676</th>\n",
       "      <td>8484936</td>\n",
       "      <td>OLO messaging active</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 08:00:00</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>OLO berichtenverkeer actief</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:24:13+01:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59677</th>\n",
       "      <td>8484936</td>\n",
       "      <td>send confirmation receipt</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 08:00:00</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>versturen ontvangstbevestiging</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:24:13+01:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59678</th>\n",
       "      <td>8484936</td>\n",
       "      <td>phase application received</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 08:00:00</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>fase aanvraag ontvangen</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:24:13+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59679</th>\n",
       "      <td>8484936</td>\n",
       "      <td>send confirmation receipt</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 08:00:00</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>versturen ontvangstbevestiging</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:24:18+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59680</th>\n",
       "      <td>8484936</td>\n",
       "      <td>enter senddate acknowledgement</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-03-04 23:28:08</td>\n",
       "      <td>Variant 3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>invoeren verzenddatum ontvangstbevestiging</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-03-05T15:28:08+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.468889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59681 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case ID                          Activity  Resource  \\\n",
       "0      3004646  register submission date request    560922   \n",
       "1      3004646    enter senddate acknowledgement    560922   \n",
       "2      3004646        phase application received    560922   \n",
       "3      3004646             reception through OLO    560922   \n",
       "4      3004646         send confirmation receipt    560922   \n",
       "...        ...                               ...       ...   \n",
       "59676  8484936              OLO messaging active    560749   \n",
       "59677  8484936         send confirmation receipt    560749   \n",
       "59678  8484936        phase application received    560749   \n",
       "59679  8484936         send confirmation receipt    560749   \n",
       "59680  8484936    enter senddate acknowledgement    560749   \n",
       "\n",
       "        Complete Timestamp     Variant  Variant index  (case) IDofConceptCase  \\\n",
       "0      2010-10-04 07:00:00  Variant 17             17                     NaN   \n",
       "1      2010-10-06 07:00:00  Variant 17             17                     NaN   \n",
       "2      2010-10-25 21:28:53  Variant 17             17                     NaN   \n",
       "3      2010-10-25 21:29:03  Variant 17             17                     NaN   \n",
       "4      2010-10-25 21:29:12  Variant 17             17                     NaN   \n",
       "...                    ...         ...            ...                     ...   \n",
       "59676  2015-03-04 08:00:00   Variant 3              3                     NaN   \n",
       "59677  2015-03-04 08:00:00   Variant 3              3                     NaN   \n",
       "59678  2015-03-04 08:00:00   Variant 3              3                     NaN   \n",
       "59679  2015-03-04 08:00:00   Variant 3              3                     NaN   \n",
       "59680  2015-03-04 23:28:08   Variant 3              3                     NaN   \n",
       "\n",
       "      (case) Includes_subCases  (case) Responsible_actor  (case) SUMleges  \\\n",
       "0                            N                    560922              NaN   \n",
       "1                            N                    560922              NaN   \n",
       "2                            N                    560922              NaN   \n",
       "3                            N                    560922              NaN   \n",
       "4                            N                    560922              NaN   \n",
       "...                        ...                       ...              ...   \n",
       "59676                     None                    560696              NaN   \n",
       "59677                     None                    560696              NaN   \n",
       "59678                     None                    560696              NaN   \n",
       "59679                     None                    560696              NaN   \n",
       "59680                     None                    560696              NaN   \n",
       "\n",
       "       ...                              activityNameNL         dateFinished  \\\n",
       "0      ...      registratie datum binnenkomst aanvraag  2010-10-25 14:38:39   \n",
       "1      ...  invoeren verzenddatum ontvangstbevestiging  2010-10-25 14:38:38   \n",
       "2      ...                     fase aanvraag ontvangen  2010-10-25 14:38:39   \n",
       "3      ...                           ontvangst via OLO  2010-10-25 14:38:39   \n",
       "4      ...              versturen ontvangstbevestiging  2010-10-25 14:38:38   \n",
       "...    ...                                         ...                  ...   \n",
       "59676  ...                 OLO berichtenverkeer actief  2015-03-04 00:00:00   \n",
       "59677  ...              versturen ontvangstbevestiging  2015-03-04 00:00:00   \n",
       "59678  ...                     fase aanvraag ontvangen  2015-03-04 00:00:00   \n",
       "59679  ...              versturen ontvangstbevestiging  2015-03-04 00:00:00   \n",
       "59680  ...  invoeren verzenddatum ontvangstbevestiging  2015-03-04 00:00:00   \n",
       "\n",
       "       dateStop                    dueDate monitoringResource  \\\n",
       "0           NaN  2010-10-11T12:00:06+02:00             560922   \n",
       "1           NaN  2010-10-27T14:29:12+02:00             560922   \n",
       "2           NaN                        NaN             560922   \n",
       "3           NaN  2010-10-28T14:28:53+02:00             560922   \n",
       "4           NaN  2010-10-27T14:29:03+02:00             560922   \n",
       "...         ...                        ...                ...   \n",
       "59676       NaN                        NaN             560696   \n",
       "59677       NaN                        NaN             560696   \n",
       "59678       NaN                        NaN             560696   \n",
       "59679       NaN                        NaN             560696   \n",
       "59680       NaN                        NaN             560696   \n",
       "\n",
       "                         planned           question Label Accepted    duration  \n",
       "0      2010-10-09T12:00:06+02:00  4-10-2010 0:00:00     1        1    0.000000  \n",
       "1      2010-10-26T14:29:12+02:00              EMPTY     1        1   48.000000  \n",
       "2                            NaN              EMPTY     1        1  470.481389  \n",
       "3      2010-10-26T14:28:53+02:00              False     1        1    0.002778  \n",
       "4      2010-10-26T14:29:03+02:00              EMPTY     1        1    0.002500  \n",
       "...                          ...                ...   ...      ...         ...  \n",
       "59676  2015-03-05T15:24:13+01:00              False     0        1  312.000000  \n",
       "59677  2015-03-05T15:24:13+01:00               True     0        1    0.000000  \n",
       "59678  2015-03-05T15:24:13+01:00              EMPTY     0        1    0.000000  \n",
       "59679  2015-03-05T15:24:18+01:00              EMPTY     0        1    0.000000  \n",
       "59680  2015-03-05T15:28:08+01:00              EMPTY     0        1   15.468889  \n",
       "\n",
       "[59681 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add duration column\n",
    "\n",
    "df = raw_df.drop(['concept:name', 'lifecycle:transition'], axis = 1)\n",
    "\n",
    "duration = [0]\n",
    "for j in range(len(df)-1):\n",
    "    \n",
    "    if df.iloc[j]['Case ID'] == df.iloc[j+1]['Case ID']:\n",
    "        x = pd.to_datetime(df.iloc[j]['Complete Timestamp']).timestamp()\n",
    "        y = pd.to_datetime(df.iloc[j+1]['Complete Timestamp']).timestamp()\n",
    "        duration.append((y-x)/3600)\n",
    "    else:\n",
    "        duration.append(0)\n",
    "        \n",
    "ts_df = pd.DataFrame(duration, columns = ['duration'])\n",
    "df = pd.concat([df, ts_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ByNb_DinnSrt"
   },
   "outputs": [],
   "source": [
    "df = df[df['Activity']!='send confirmation receipt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NQnkqW_fnSrt"
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\Dias\\Desktop\\data\\dataset\\BPIC15_3_dur.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOQaV5nOnSru"
   },
   "source": [
    "# prefixlength_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRI_muZGnSrw",
    "outputId": "982ac934-d1ea-4afe-e69a-522d0e184add",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1409/1409 [00:00<00:00, 2759.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1409/1409 [00:00<00:00, 3457.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1409/1409 [00:00<00:00, 3931.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1409/1409 [00:00<00:00, 4012.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1409/1409 [00:00<00:00, 4115.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1409/1409 [00:00<00:00, 4044.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1409/1409 [00:00<00:00, 3724.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1409/1409 [00:00<00:00, 5557.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "#from playsound import playsound\n",
    "import warnings\n",
    "\n",
    "\n",
    "def morethan(df,length):\n",
    "    #df['END_DATE'] = pd.to_datetime(df['END_DATE'])\n",
    "    groups = df.groupby('Case ID')\n",
    "    lenmorethan=[]\n",
    "    \n",
    "    for case, group in tqdm(groups):\n",
    "        #group = group.sort_values(by='remaining_time', ascending = False).reset_index(drop=True)\n",
    "        if len(group) >= length:\n",
    "            addgroup = group.iloc[:length,:]\n",
    "            #print(addgroup)\n",
    "            #activitylist = list(addgroup['ACTIVITY'])\n",
    "            lenmorethan.append(addgroup)\n",
    "    df = pd.concat(lenmorethan)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    warnings.filterwarnings(action='ignore')\n",
    "    for x in range(5, 41, 5):\n",
    "        length = x \n",
    "        df = pd.read_csv(r'C:\\Users\\Dias\\Desktop\\data\\dataset\\BPIC15_3_dur.csv')\n",
    "        df = morethan(df,length)\n",
    "        \n",
    "        dir_path = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\prefix'+str(length)\n",
    "        try:\n",
    "            os.makedirs(dir_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        df.to_csv(dir_path+r'\\bpic2015_3_prep.csv',index=False)\n",
    "    #playsound('../Yattong edited version.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wd990FOPnSrx",
    "outputId": "e6bb3ed3-36d8-4603-c600-7050d8420601"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Resource</th>\n",
       "      <th>Complete Timestamp</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Variant index</th>\n",
       "      <th>(case) IDofConceptCase</th>\n",
       "      <th>(case) Includes_subCases</th>\n",
       "      <th>(case) Responsible_actor</th>\n",
       "      <th>(case) SUMleges</th>\n",
       "      <th>...</th>\n",
       "      <th>activityNameNL</th>\n",
       "      <th>dateFinished</th>\n",
       "      <th>dateStop</th>\n",
       "      <th>dueDate</th>\n",
       "      <th>monitoringResource</th>\n",
       "      <th>planned</th>\n",
       "      <th>question</th>\n",
       "      <th>Label</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3025465</td>\n",
       "      <td>register submission date request</td>\n",
       "      <td>560749</td>\n",
       "      <td>2010-10-14 07:00:00</td>\n",
       "      <td>Variant 20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>registratie datum binnenkomst aanvraag</td>\n",
       "      <td>2010-10-27 16:07:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-30T16:05:38+02:00</td>\n",
       "      <td>560719</td>\n",
       "      <td>2010-10-28T16:05:38+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3025465</td>\n",
       "      <td>enter senddate acknowledgement</td>\n",
       "      <td>560749</td>\n",
       "      <td>2010-10-18 07:00:00</td>\n",
       "      <td>Variant 20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>invoeren verzenddatum ontvangstbevestiging</td>\n",
       "      <td>2010-10-27 16:07:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-29T16:05:56+02:00</td>\n",
       "      <td>560719</td>\n",
       "      <td>2010-10-28T16:05:56+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3025465</td>\n",
       "      <td>enter senddate procedure confirmation</td>\n",
       "      <td>560749</td>\n",
       "      <td>2010-10-18 07:00:00</td>\n",
       "      <td>Variant 20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>invoeren verzenddatum procedurebevestiging</td>\n",
       "      <td>2010-10-27 16:07:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560719</td>\n",
       "      <td>2010-10-28T16:06:59+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3025465</td>\n",
       "      <td>registrer date of publishing received request</td>\n",
       "      <td>560749</td>\n",
       "      <td>2010-10-27 07:00:00</td>\n",
       "      <td>Variant 20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>registratie datum publicatie ingekomen aanvraag</td>\n",
       "      <td>2010-10-27 17:17:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560719</td>\n",
       "      <td>2010-10-28T16:08:06+02:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3025465</td>\n",
       "      <td>phase application received</td>\n",
       "      <td>560749</td>\n",
       "      <td>2010-10-27 23:05:45</td>\n",
       "      <td>Variant 20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>560719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>fase aanvraag ontvangen</td>\n",
       "      <td>2010-10-27 16:07:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.095833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57000</th>\n",
       "      <td>8384851</td>\n",
       "      <td>phase decision sent</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-02-25 08:00:00</td>\n",
       "      <td>Variant 1343</td>\n",
       "      <td>1343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>11.25405</td>\n",
       "      <td>...</td>\n",
       "      <td>fase beschikking verzonden</td>\n",
       "      <td>2015-02-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-02-26T14:08:14+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57001</th>\n",
       "      <td>8384851</td>\n",
       "      <td>start decision phase decision permitting sent</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-02-25 08:00:00</td>\n",
       "      <td>Variant 1343</td>\n",
       "      <td>1343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>11.25405</td>\n",
       "      <td>...</td>\n",
       "      <td>instellen besluitfase:besluit vergunnen verzonden</td>\n",
       "      <td>2015-02-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-02-26T14:08:12+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57002</th>\n",
       "      <td>8384851</td>\n",
       "      <td>phase decision taken</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-02-25 08:00:00</td>\n",
       "      <td>Variant 1343</td>\n",
       "      <td>1343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>11.25405</td>\n",
       "      <td>...</td>\n",
       "      <td>fase besluit genomen</td>\n",
       "      <td>2015-02-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-02-26T14:05:26+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57003</th>\n",
       "      <td>8384851</td>\n",
       "      <td>record date of decision environmental permit</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-02-25 22:05:24</td>\n",
       "      <td>Variant 1343</td>\n",
       "      <td>1343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>11.25405</td>\n",
       "      <td>...</td>\n",
       "      <td>registreren datum besluit omgevingsvergunning2</td>\n",
       "      <td>2015-02-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-02-26T14:05:24+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57004</th>\n",
       "      <td>8384851</td>\n",
       "      <td>enter senddate decision environmental permit</td>\n",
       "      <td>560749</td>\n",
       "      <td>2015-02-25 22:08:11</td>\n",
       "      <td>Variant 1343</td>\n",
       "      <td>1343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>560696</td>\n",
       "      <td>11.25405</td>\n",
       "      <td>...</td>\n",
       "      <td>invoeren verzenddatum beschikking omgevingsver...</td>\n",
       "      <td>2015-02-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560696</td>\n",
       "      <td>2015-02-26T14:08:11+01:00</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31400 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case ID                                       Activity  Resource  \\\n",
       "91     3025465               register submission date request    560749   \n",
       "92     3025465                 enter senddate acknowledgement    560749   \n",
       "93     3025465          enter senddate procedure confirmation    560749   \n",
       "94     3025465  registrer date of publishing received request    560749   \n",
       "95     3025465                     phase application received    560749   \n",
       "...        ...                                            ...       ...   \n",
       "57000  8384851                            phase decision sent    560749   \n",
       "57001  8384851  start decision phase decision permitting sent    560749   \n",
       "57002  8384851                           phase decision taken    560749   \n",
       "57003  8384851   record date of decision environmental permit    560749   \n",
       "57004  8384851   enter senddate decision environmental permit    560749   \n",
       "\n",
       "        Complete Timestamp       Variant  Variant index  \\\n",
       "91     2010-10-14 07:00:00    Variant 20             20   \n",
       "92     2010-10-18 07:00:00    Variant 20             20   \n",
       "93     2010-10-18 07:00:00    Variant 20             20   \n",
       "94     2010-10-27 07:00:00    Variant 20             20   \n",
       "95     2010-10-27 23:05:45    Variant 20             20   \n",
       "...                    ...           ...            ...   \n",
       "57000  2015-02-25 08:00:00  Variant 1343           1343   \n",
       "57001  2015-02-25 08:00:00  Variant 1343           1343   \n",
       "57002  2015-02-25 08:00:00  Variant 1343           1343   \n",
       "57003  2015-02-25 22:05:24  Variant 1343           1343   \n",
       "57004  2015-02-25 22:08:11  Variant 1343           1343   \n",
       "\n",
       "       (case) IDofConceptCase (case) Includes_subCases  \\\n",
       "91                        NaN                        N   \n",
       "92                        NaN                        N   \n",
       "93                        NaN                        N   \n",
       "94                        NaN                        N   \n",
       "95                        NaN                        N   \n",
       "...                       ...                      ...   \n",
       "57000                     NaN                     None   \n",
       "57001                     NaN                     None   \n",
       "57002                     NaN                     None   \n",
       "57003                     NaN                     None   \n",
       "57004                     NaN                     None   \n",
       "\n",
       "       (case) Responsible_actor  (case) SUMleges  ...  \\\n",
       "91                       560719              NaN  ...   \n",
       "92                       560719              NaN  ...   \n",
       "93                       560719              NaN  ...   \n",
       "94                       560719              NaN  ...   \n",
       "95                       560719              NaN  ...   \n",
       "...                         ...              ...  ...   \n",
       "57000                    560696         11.25405  ...   \n",
       "57001                    560696         11.25405  ...   \n",
       "57002                    560696         11.25405  ...   \n",
       "57003                    560696         11.25405  ...   \n",
       "57004                    560696         11.25405  ...   \n",
       "\n",
       "                                          activityNameNL         dateFinished  \\\n",
       "91                registratie datum binnenkomst aanvraag  2010-10-27 16:07:20   \n",
       "92            invoeren verzenddatum ontvangstbevestiging  2010-10-27 16:07:20   \n",
       "93            invoeren verzenddatum procedurebevestiging  2010-10-27 16:07:20   \n",
       "94       registratie datum publicatie ingekomen aanvraag  2010-10-27 17:17:45   \n",
       "95                               fase aanvraag ontvangen  2010-10-27 16:07:21   \n",
       "...                                                  ...                  ...   \n",
       "57000                         fase beschikking verzonden  2015-02-25 00:00:00   \n",
       "57001  instellen besluitfase:besluit vergunnen verzonden  2015-02-25 00:00:00   \n",
       "57002                               fase besluit genomen  2015-02-25 00:00:00   \n",
       "57003     registreren datum besluit omgevingsvergunning2  2015-02-25 00:00:00   \n",
       "57004  invoeren verzenddatum beschikking omgevingsver...  2015-02-25 00:00:00   \n",
       "\n",
       "       dateStop                    dueDate monitoringResource  \\\n",
       "91          NaN  2010-10-30T16:05:38+02:00             560719   \n",
       "92          NaN  2010-10-29T16:05:56+02:00             560719   \n",
       "93          NaN                        NaN             560719   \n",
       "94          NaN                        NaN             560719   \n",
       "95          NaN                        NaN             560719   \n",
       "...         ...                        ...                ...   \n",
       "57000       NaN                        NaN             560696   \n",
       "57001       NaN                        NaN             560696   \n",
       "57002       NaN                        NaN             560696   \n",
       "57003       NaN                        NaN             560696   \n",
       "57004       NaN                        NaN             560696   \n",
       "\n",
       "                         planned  question Label Accepted    duration  \n",
       "91     2010-10-28T16:05:38+02:00     EMPTY     0        1    0.000000  \n",
       "92     2010-10-28T16:05:56+02:00     EMPTY     0        1   96.000000  \n",
       "93     2010-10-28T16:06:59+02:00     EMPTY     0        1    0.000000  \n",
       "94     2010-10-28T16:08:06+02:00     EMPTY     0        1  216.000000  \n",
       "95                           NaN     EMPTY     0        1   16.095833  \n",
       "...                          ...       ...   ...      ...         ...  \n",
       "57000  2015-02-26T14:08:14+01:00     EMPTY     0        1    0.000000  \n",
       "57001  2015-02-26T14:08:12+01:00     EMPTY     0        1    0.000000  \n",
       "57002  2015-02-26T14:05:26+01:00     EMPTY     0        1    0.000000  \n",
       "57003  2015-02-26T14:05:24+01:00     EMPTY     0        1   14.090000  \n",
       "57004  2015-02-26T14:08:11+01:00     EMPTY     0        1    0.046389  \n",
       "\n",
       "[31400 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQHcWkgznSry"
   },
   "source": [
    "# indexbase.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmIW86VanSrz",
    "outputId": "58cb7075-9397-4918-ea43-3ceb33c85f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix length : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                          | 80/1363 [00:00<00:01, 775.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start event categorical attribute OHE preprocessing.... \n",
      "\n",
      "Activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1363/1363 [00:01<00:00, 705.18it/s]\n",
      "  5%|███▋                                                                           | 63/1363 [00:00<00:02, 623.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1363/1363 [00:01<00:00, 744.15it/s]\n",
      "  6%|████▋                                                                          | 81/1363 [00:00<00:01, 755.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoringResource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1363/1363 [00:01<00:00, 740.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Case categorical attribute OHE preprocessing.... \n",
      "\n",
      "Start Case continuous attribute OHE preprocessing.... \n",
      "\n",
      "(case) SUMleges\n",
      "5 (case) SUMleges \n",
      " 1/3 point :  188.38521000000003 ,  2/3 point :  957.648000000001\n",
      "Start y value extraction preprocessing.... \n",
      "\n",
      "Prefix length : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▌                                                                          | 75/1311 [00:00<00:01, 710.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start event categorical attribute OHE preprocessing.... \n",
      "\n",
      "Activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1311/1311 [00:01<00:00, 749.58it/s]\n",
      "  6%|█████                                                                          | 85/1311 [00:00<00:01, 843.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1311/1311 [00:01<00:00, 752.96it/s]\n",
      "  5%|████▎                                                                          | 71/1311 [00:00<00:01, 679.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoringResource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1311/1311 [00:01<00:00, 718.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Case categorical attribute OHE preprocessing.... \n",
      "\n",
      "Start Case continuous attribute OHE preprocessing.... \n",
      "\n",
      "(case) SUMleges\n",
      "10 (case) SUMleges \n",
      " 1/3 point :  190.518 ,  2/3 point :  976.1940000000013\n",
      "Start y value extraction preprocessing.... \n",
      "\n",
      "Prefix length : 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                           | 65/1285 [00:00<00:01, 648.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start event categorical attribute OHE preprocessing.... \n",
      "\n",
      "Activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1285/1285 [00:01<00:00, 718.80it/s]\n",
      "  6%|████▊                                                                          | 78/1285 [00:00<00:01, 675.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1285/1285 [00:01<00:00, 702.65it/s]\n",
      "  6%|████▉                                                                          | 80/1285 [00:00<00:01, 733.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoringResource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1285/1285 [00:01<00:00, 712.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Case categorical attribute OHE preprocessing.... \n",
      "\n",
      "Start Case continuous attribute OHE preprocessing.... \n",
      "\n",
      "(case) SUMleges\n",
      "15 (case) SUMleges \n",
      " 1/3 point :  190.35501666666667 ,  2/3 point :  957.648000000001\n",
      "Start y value extraction preprocessing.... \n",
      "\n",
      "Prefix length : 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                          | 78/1251 [00:00<00:01, 743.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start event categorical attribute OHE preprocessing.... \n",
      "\n",
      "Activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1251/1251 [00:01<00:00, 723.84it/s]\n",
      "  6%|████▍                                                                          | 71/1251 [00:00<00:01, 700.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1251/1251 [00:01<00:00, 714.40it/s]\n",
      " 11%|████████▌                                                                     | 137/1251 [00:00<00:01, 666.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoringResource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1251/1251 [00:01<00:00, 705.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Case categorical attribute OHE preprocessing.... \n",
      "\n",
      "Start Case continuous attribute OHE preprocessing.... \n",
      "\n",
      "(case) SUMleges\n",
      "20 (case) SUMleges \n",
      " 1/3 point :  190.19203333333337 ,  2/3 point :  966.9210000000021\n",
      "Start y value extraction preprocessing.... \n",
      "\n",
      "Prefix length : 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                           | 59/1223 [00:00<00:01, 588.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start event categorical attribute OHE preprocessing.... \n",
      "\n",
      "Activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1223/1223 [00:01<00:00, 710.73it/s]\n",
      "  4%|███▍                                                                           | 53/1223 [00:00<00:02, 517.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1223/1223 [00:02<00:00, 562.48it/s]\n",
      "  9%|██████▋                                                                      | 107/1223 [00:00<00:01, 1054.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoringResource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1223/1223 [00:02<00:00, 573.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Case categorical attribute OHE preprocessing.... \n",
      "\n",
      "Start Case continuous attribute OHE preprocessing.... \n",
      "\n",
      "(case) SUMleges\n",
      "25 (case) SUMleges \n",
      " 1/3 point :  190.19203333333337 ,  2/3 point :  984.0732666666676\n",
      "Start y value extraction preprocessing.... \n",
      "\n",
      "Prefix length : 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                        | 95/1195 [00:00<00:01, 938.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start event categorical attribute OHE preprocessing.... \n",
      "\n",
      "Activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1195/1195 [00:01<00:00, 940.97it/s]\n",
      "  8%|██████▎                                                                        | 95/1195 [00:00<00:01, 945.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1195/1195 [00:01<00:00, 696.32it/s]\n",
      " 11%|████████▍                                                                     | 130/1195 [00:00<00:01, 650.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoringResource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1195/1195 [00:01<00:00, 698.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Case categorical attribute OHE preprocessing.... \n",
      "\n",
      "Start Case continuous attribute OHE preprocessing.... \n",
      "\n",
      "(case) SUMleges\n",
      "30 (case) SUMleges \n",
      " 1/3 point :  190.19203333333337 ,  2/3 point :  984.0732666666676\n",
      "Start y value extraction preprocessing.... \n",
      "\n",
      "Prefix length : 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                           | 57/1128 [00:00<00:01, 566.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start event categorical attribute OHE preprocessing.... \n",
      "\n",
      "Activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1128/1128 [00:01<00:00, 723.47it/s]\n",
      " 16%|████████████▌                                                                 | 181/1128 [00:00<00:01, 909.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1128/1128 [00:01<00:00, 713.95it/s]\n",
      "  4%|███▌                                                                           | 50/1128 [00:00<00:02, 497.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoringResource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1128/1128 [00:01<00:00, 671.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Case categorical attribute OHE preprocessing.... \n",
      "\n",
      "Start Case continuous attribute OHE preprocessing.... \n",
      "\n",
      "(case) SUMleges\n",
      "35 (case) SUMleges \n",
      " 1/3 point :  189.4558166666667 ,  2/3 point :  984.0732666666676\n",
      "Start y value extraction preprocessing.... \n",
      "\n",
      "Prefix length : 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▌                                                                         | 65/785 [00:00<00:01, 607.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start event categorical attribute OHE preprocessing.... \n",
      "\n",
      "Activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 785/785 [00:01<00:00, 658.61it/s]\n",
      "  8%|██████                                                                          | 60/785 [00:00<00:01, 595.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 785/785 [00:01<00:00, 685.78it/s]\n",
      "  8%|██████▌                                                                         | 65/785 [00:00<00:01, 623.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoringResource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 785/785 [00:01<00:00, 662.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Case categorical attribute OHE preprocessing.... \n",
      "\n",
      "Start Case continuous attribute OHE preprocessing.... \n",
      "\n",
      "(case) SUMleges\n",
      "40 (case) SUMleges \n",
      " 1/3 point :  178.71599999999998 ,  2/3 point :  1142.265\n",
      "Start y value extraction preprocessing.... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import os \n",
    "import multiprocessing\n",
    "from multiprocessing import Pool,cpu_count\n",
    "#from playsound import playsound\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "def indexbase(df,prefix): #Activity index base encoding ex) e1_a, e1_b, e2_d,e2_f...\n",
    "    print('Start index base preprocessing.... \\n')\n",
    "    groups = df.groupby('Case ID')\n",
    "    prefixlength =  prefix\n",
    "    obj = {}\n",
    "    case_name =[]\n",
    "\n",
    "    for i in range(prefixlength):\n",
    "        name = 'event'+str(i+1)\n",
    "        obj[name]=[]\n",
    "\n",
    "    length2 = len(set(df['Case ID']))\n",
    "    for case,group in tqdm(groups):\n",
    "        group = group.sort_values('Complete Timestamp').reset_index(drop=True)\n",
    "        actlist = list(group['Activity'])\n",
    "        case_name.append(case)\n",
    "        for pos,act in enumerate(actlist):\n",
    "            name = 'event'+str(pos+1)\n",
    "            obj[name].append(act)\n",
    "    dfk = pd.DataFrame(obj)\n",
    "    columns = list(dfk.columns)\n",
    "    concating=[]\n",
    "    for col in columns:\n",
    "        concating.append(pd.get_dummies(dfk[col],prefix=col))\n",
    "    dfk = pd.concat(concating,axis=1)\n",
    "    dfk['Case ID'] = case_name\n",
    "    return dfk\n",
    "\n",
    "def case_att_cat_onehot(df,columns): #Case attribute categorical column one hot encoding\n",
    "    '''\n",
    "    columns : list type object\n",
    "    '''\n",
    "\n",
    "    print('Start Case categorical attribute OHE preprocessing.... \\n')\n",
    "    groups = df.groupby('Case ID').first()\n",
    "    concating =[]\n",
    "    case =[]\n",
    "    for col in columns:\n",
    "        concating.append(pd.get_dummies(groups[col],prefix=col.capitalize()))\n",
    "    dfk =pd.concat(concating,axis=1).reset_index(drop=True)\n",
    "    dfk['Case ID'] = list(groups.index.values)\n",
    "    return dfk\n",
    "\n",
    "def case_att_con_onehot(df,columns): #Case attribute categorical column one hot encoding\n",
    "    '''\n",
    "    columns : list type object\n",
    "    '''\n",
    "    \n",
    "    print('Start Case continuous attribute OHE preprocessing.... \\n')\n",
    "    groups = df.groupby('Case ID').first()\n",
    "    concating=[]\n",
    "    obj ={}\n",
    "    for col in columns:\n",
    "        if df[col].isnull().sum() == len(df):\n",
    "            pass\n",
    "        else:\n",
    "            print(col)\n",
    "            toput = []\n",
    "            for x in list(groups[col]):\n",
    "                if math.isnan(x):\n",
    "                    pass\n",
    "                else:\n",
    "                    toput.append(x)\n",
    "            obj[col] = toput\n",
    "            \n",
    "\n",
    "            shortpoint = np.percentile(obj[col],100/3)\n",
    "            midpoint = np.percentile(obj[col],200/3)\n",
    "\n",
    "            obj2={}\n",
    "\n",
    "            length2 = len(set(df['Case ID']))\n",
    "\n",
    "            print(prefix, col, '\\n', '1/3 point : ',shortpoint, ',  2/3 point : ',midpoint)\n",
    "\n",
    "            categorizedlist=[]\n",
    "            targetcol = list(groups[col])\n",
    "            for target in targetcol:\n",
    "                if target < shortpoint:\n",
    "                    categorizedlist.append('L-'+str(shortpoint))\n",
    "                elif target >= shortpoint and target < midpoint:\n",
    "                    categorizedlist.append('L-'+str(shortpoint)+'U-'+str(midpoint))\n",
    "                elif target >= midpoint:\n",
    "                    categorizedlist.append('U-'+str(midpoint))\n",
    "                else:\n",
    "                    categorizedlist.append('Nan')\n",
    "\n",
    "            groups[col] = categorizedlist\n",
    "            dfk = pd.get_dummies(groups[col],prefix=col)\n",
    "            if len(columns) ==1:\n",
    "                pass\n",
    "            else:\n",
    "                concating.append(dfk)\n",
    "        if len(columns) ==1:\n",
    "            pass\n",
    "        else:    \n",
    "            dfk = pd.concat(concating,axis=1)\n",
    "        # dfk['Case ID'] = list(df.groupby('Case ID').first().index.values)\n",
    "    return dfk\n",
    "    \n",
    "def event_att_cat_onehot(df,columns,prefix):\n",
    "    '''\n",
    "    columns : list type object\n",
    "    prefix : prefix length\n",
    "    '''\n",
    "    print('Start event categorical attribute OHE preprocessing.... \\n')\n",
    "    groups = df.groupby('Case ID')\n",
    "    prefixlength =  prefix\n",
    "\n",
    "    dropcol=[]\n",
    "    for x in columns:\n",
    "        if df[x].isnull().all():\n",
    "            dropcol.append(x)\n",
    "    columns = [x for x in columns if x not in dropcol]\n",
    "\n",
    "    allconcating=[]\n",
    "    for col in columns:\n",
    "        print(col)\n",
    "        obj = {}\n",
    "        case_name =[]\n",
    "        for i in range(prefixlength):\n",
    "            name = str(col)+str(i+1)\n",
    "            obj[name]=[]\n",
    "\n",
    "        length2 = len(set(df['Case ID']))\n",
    "       \n",
    "        for case,group in tqdm(groups):\n",
    "            group = group.sort_values('Complete Timestamp').reset_index(drop=True)\n",
    "            actlist = list(group[col])\n",
    "            case_name.append(case)\n",
    "            for pos,act in enumerate(actlist):\n",
    "                name = str(col)+str(pos+1)\n",
    "                obj[name].append(act)\n",
    "\n",
    "        dfk = pd.DataFrame(obj)\n",
    "        columns = list(dfk.columns)\n",
    "        concating=[]\n",
    "        for col in columns:\n",
    "            concating.append(pd.get_dummies(dfk[col],prefix=col))\n",
    "        dfk = pd.concat(concating,axis=1)\n",
    "\n",
    "        if len(columns) == 1:\n",
    "            pass\n",
    "        else:\n",
    "            allconcating.append(dfk)\n",
    "    if len(columns) ==1:\n",
    "        pass\n",
    "    else:\n",
    "        dfk = pd.concat(allconcating,axis=1)\n",
    "    \n",
    "    dfk['Case ID'] = case_name\n",
    "    return dfk\n",
    "\n",
    "\n",
    "def event_att_con_onehot(df,columns,prefix): #Case attribute categorical column one hot encoding\n",
    "    '''\n",
    "    columns : list type object\n",
    "    prefix : prefix length\n",
    "    '''\n",
    "\n",
    "    print('Start Event continuous attribute OHE preprocessing.... \\n')\n",
    "    groups = df.groupby('Case ID')\n",
    "    concating =[]\n",
    "    \n",
    "\n",
    "    prefixlength =  prefix\n",
    "\n",
    "    dropcol=[]\n",
    "    for x in columns:\n",
    "        if df[x].isnull().all():\n",
    "            dropcol.append(x)\n",
    "    columns = [x for x in columns if x not in dropcol]\n",
    "\n",
    "    for col in columns:\n",
    "        print(col)\n",
    "        obj = {}\n",
    "        for case, group in groups:\n",
    "            event_attribute = list(group[col])\n",
    "            for pos, att in enumerate(event_attribute):\n",
    "                name = str(col).capitalize()+str(pos+1)\n",
    "                if name not in list(obj.keys()):\n",
    "                    obj[name] = [[att],1,{},[]]\n",
    "                else:                \n",
    "                    obj[name][0].append(att)\n",
    "                    obj[name][1] +=1\n",
    "        objkey = list(obj.keys())\n",
    "\n",
    "        for key in obj.keys():\n",
    "            obj[key][0] = [x for x in obj[key][0] if ~np.isnan(x)]\n",
    "            obj[key][2]['Shortpoint'] = np.mean(obj[key][0])*0.4\n",
    "            obj[key][2]['Midpoint'] = np.mean(obj[key][0])*0.6\n",
    "\n",
    "                \n",
    "        for case, group in groups:\n",
    "            event_attribute = list(group[col])\n",
    "            for pos, att in enumerate(event_attribute):\n",
    "                name = str(col).capitalize()+str(pos+1)\n",
    "                if name not in list(obj.keys()):\n",
    "                    pass\n",
    "                else:\n",
    "                    shortpoint = obj[name][2]['Shortpoint']\n",
    "                    midpoint  = obj[name][2]['Midpoint']\n",
    "                    if att < shortpoint:\n",
    "                        obj[name][3].append('L-'+str(shortpoint))\n",
    "                    elif att >= shortpoint and att < midpoint:\n",
    "                        obj[name][3].append('L-'+str(shortpoint)+'U-'+str(midpoint))\n",
    "                    elif att > midpoint:\n",
    "                        obj[name][3].append('U-'+str(midpoint))\n",
    "                    else:\n",
    "                        obj[name][3].append('Nan')\n",
    "\n",
    "        obj2 ={x:obj[x][3] for x in obj.keys()}\n",
    "\n",
    "        dfk = pd.DataFrame(obj2)\n",
    "        columns2 = list(dfk.columns)\n",
    "        concating2=[]\n",
    "        for col in columns2:\n",
    "            concating2.append(pd.get_dummies(dfk[col],prefix=col))\n",
    "        dfk = pd.concat(concating2,axis=1)\n",
    "        concating.append(dfk)\n",
    "        print(prefix, col, '\\n', '1/3 point : ', shortpoint, ',  2/3 point : ',midpoint)\n",
    "    \n",
    "    \n",
    "    dft = pd.concat(concating,axis=1)\n",
    "    dft = dft.reset_index(drop=True)\n",
    "    dft['Case ID'] = list(df.groupby('Case ID').first().index.values)\n",
    "    \n",
    "    return dft\n",
    "\n",
    "\n",
    "def y_value(df,column):\n",
    "    print('Start y value extraction preprocessing.... \\n')\n",
    "    m_dict={'Case ID':[],column:[]}\n",
    "    df = df.rename(columns={column:'Label'})\n",
    "    \n",
    "    column = 'Label'\n",
    "    groups = df.groupby('Case ID').first()\n",
    "    \n",
    "    m_dict['Case ID']=list(groups.index.values)\n",
    "    m_dict[column] = list(groups[column])\n",
    "    dfk = pd.DataFrame(m_dict,columns=['Case ID','Label'])\n",
    "    \n",
    "    dfk = pd.concat([dfk,pd.get_dummies(dfk['Label'],prefix=column)],axis=1)\n",
    "    dfk = dfk.drop(column,axis=1)\n",
    "    return dfk\n",
    "\n",
    "def timediscretize(df,prefix): #3 cat, [short,medium,long] discretize\n",
    "    print('Start time discretization preprocessing.... \\n')\n",
    "    df['Complete Timestamp'] =  pd.to_datetime(df['Complete Timestamp'])\n",
    "    timeorder = {}\n",
    "    groups = df.groupby('Case ID')\n",
    "\n",
    "    length2 = len(set(df['Case ID']))\n",
    "\n",
    "    for case,group in tqdm(groups):\n",
    "        group = group.sort_values('Complete Timestamp').reset_index(drop=True)\n",
    "        actlist = list(group['Activity'])\n",
    "        length = len(group)\n",
    "        timestamp =list(group['Complete Timestamp'])\n",
    "        for pos, x in enumerate(actlist):\n",
    "            if pos+1 != length:\n",
    "                if ((x,actlist[pos+1])) not in list(timeorder.keys()):\n",
    "                    timeorder[(x,actlist[pos+1])] =[[(timestamp[pos+1]- timestamp[pos]).total_seconds() / 3600],1,{}]\n",
    "                else:\n",
    "                    timeorder[(x,actlist[pos+1])][0].append((timestamp[pos+1]- timestamp[pos]).total_seconds() / 3600)\n",
    "                    timeorder[(x,actlist[pos+1])][1] +=1\n",
    "    \n",
    "    duration = [0]\n",
    "    for j in range(len(df)-1):\n",
    "\n",
    "        if df.iloc[j]['Case ID'] == df.iloc[j+1]['Case ID']:\n",
    "            x = pd.to_datetime(df.iloc[j]['Complete Timestamp']).timestamp()\n",
    "            y = pd.to_datetime(df.iloc[j+1]['Complete Timestamp']).timestamp()\n",
    "            duration.append((y-x)/3600)\n",
    "        else:\n",
    "            duration.append(0)\n",
    "\n",
    "    non_zero  = []\n",
    "    for j in range(len(duration)):\n",
    "        if duration[j] != 0:\n",
    "            non_zero.append(duration[j])\n",
    "\n",
    "    shortpoint = np.percentile(non_zero,100/3)\n",
    "    midpoint = np.percentile(non_zero,200/3)\n",
    "\n",
    "    print(prefix, shortpoint, midpoint)\n",
    "\n",
    "\n",
    "    df['Complete Timestamp'] =  pd.to_datetime(df['Complete Timestamp'])\n",
    "    prefixlength =  prefix\n",
    "    obj = {}\n",
    "    case_name =[]\n",
    "    for i in range(prefixlength-1):\n",
    "        name = 'Time'+str(i+1)\n",
    "        obj[name]=[]\n",
    "\n",
    "    length2 = len(set(df['Case ID']))\n",
    "\n",
    "    for case,group in groups:\n",
    "        group = group.sort_values('Complete Timestamp').reset_index(drop=True)\n",
    "        actlist = list(group['Activity'])\n",
    "        case_name.append(case)\n",
    "        timestamp =list(group['Complete Timestamp'])\n",
    "        for pos,x in enumerate(actlist):\n",
    "            if pos+1 != length:\n",
    "                actpair = ((x,actlist[pos+1]))\n",
    "                timedifference = (timestamp[pos] - timestamp[pos-1]).total_seconds() /3600\n",
    "                name = 'Time'+str(pos+1)\n",
    "                if timedifference < shortpoint:\n",
    "                    obj[name].append('L-'+str(shortpoint))\n",
    "                elif timedifference >= shortpoint and timedifference < midpoint:\n",
    "                    obj[name].append('L-'+str(shortpoint)+'U-'+str(midpoint))\n",
    "                elif timedifference >= midpoint:\n",
    "                    obj[name].append('U-'+str(midpoint))\n",
    "                else:\n",
    "                    obj[name].append('all0')\n",
    "            \n",
    "    dfk = pd.DataFrame(obj)\n",
    "    columns = list(dfk.columns)\n",
    "    concating=[]\n",
    "    for col in columns:\n",
    "        concating.append(pd.get_dummies(dfk[col],prefix=col))\n",
    "    dfk = pd.concat(concating,axis=1)\n",
    "    dfk['Case ID'] = case_name    \n",
    "    \n",
    "\n",
    "    return dfk\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    for k in range(5, 41, 5):\n",
    "        prefix = k\n",
    "        print('Prefix length : %s'%(prefix))\n",
    "\n",
    "        dirname = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/prefix'+str(prefix)\n",
    "        df = pd.read_csv(dirname+'/bpic2015_3_prep.csv')\n",
    "\n",
    "        \n",
    "        case_att_cat = ['(case) Includes_subCases','(case) Responsible_actor','(case) caseProcedure','(case) caseStatus','(case) last_phase','(case) parts',\n",
    "                        '(case) requestComplete','(case) termName']\n",
    "        case_att_con = ['(case) SUMleges']\n",
    "        event_att_cat = ['Activity','Resource', 'monitoringResource']\n",
    "\n",
    "            \n",
    "        savedir = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\RIPPER\\prefix'+str(prefix)+''\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(savedir)\n",
    "        except:\n",
    "            pass        \n",
    "        \n",
    "        y_column = 'Label'\n",
    "\n",
    "        event = {}\n",
    "        \n",
    "        for p in range(prefix):\n",
    "            dict_index = 'duration{}'.format(p+1)\n",
    "            event[dict_index] = []\n",
    "            for case, group in df.groupby('Case ID'):\n",
    "                dur_list = group['duration'].tolist()\n",
    "                event[dict_index].append(dur_list[p])\n",
    "        \n",
    "        groups = df.groupby('Case ID').first()\n",
    "        event['Case ID'] = list(groups.index.values)\n",
    "        event['Accepted'] = list(groups.Accepted.values)\n",
    "        event['Complete Timestamp'] = df.groupby('Case ID').tail(1)['Complete Timestamp']\n",
    "\n",
    "        dur_df = pd.DataFrame.from_dict(event)\n",
    "        \n",
    "        dfs = [dur_df, event_att_cat_onehot(df,event_att_cat,prefix),case_att_cat_onehot(df,case_att_cat),case_att_con_onehot(df,case_att_con), y_value(df,y_column)]\n",
    "\n",
    "        \n",
    "        df_final = reduce(lambda  left,right: pd.merge(left,right,on='Case ID'),dfs)\n",
    "\n",
    "\n",
    "        df_final.to_csv(savedir +'/BPICinput_preprocessed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkIFIuoJnSr6"
   },
   "source": [
    "# trainsplit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OD7aSP7dnSr8",
    "outputId": "d94b7c41-d9c6-4ad0-bdb9-8d38a1df8db6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:54<00:00,  6.76s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "for prefix in tqdm(range(5, 41, 5)):\n",
    "\n",
    "    dir_path = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\RIPPER\\prefix'+str(prefix)+''\n",
    "    df = pd.read_csv(dir_path+'/BPICinput_preprocessed.csv')\n",
    "    df['Complete Timestamp'] =  pd.to_datetime(df['Complete Timestamp'])\n",
    "    df = df.sort_values('Complete Timestamp').reset_index(drop=True)\n",
    "    \n",
    "    for rndst in range(0,5):\n",
    "        df_train,df_test = train_test_split(df,test_size=0.3, shuffle=False, random_state=rndst) #Random State 0,1,2,3,4,5,6,7,8,9 10 numbers\n",
    "        df_train.to_csv(dir_path+'/train_rndst'+str(rndst)+'.csv',index=False)\n",
    "        df_test.to_csv(dir_path+'/test_rndst'+str(rndst)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Wo54oWOnSr9",
    "outputId": "c4966ed5-6030-4a1d-ecfd-e7c147729ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549, 4495) (236, 4495)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape,df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf3MGmPZoNRf"
   },
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Zirk5OdnoQmm",
    "outputId": "6d6cb930-d069-4a74-e7c7-a92b5240fdb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "{'Label 0': {'precision': [1.0, 0.0], 'recall': [0.9539473684210528, 1.1102230246251565e-16], 'f1-score': [0.9764309764309764, 0.0], 'support': [304.0, 0.0]}, 'Label 1': {'precision': [0.8823529411764707, 1.1102230246251565e-16], 'recall': [1.0, 0.0], 'f1-score': [0.9375, 0.0], 'support': [105.0, 0.0]}}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "{'Label 0': {'precision': [1.0, 0.0], 'recall': [0.954861111111111, 1.1102230246251565e-16], 'f1-score': [0.9769094138543517, 0.0], 'support': [288.0, 0.0]}, 'Label 1': {'precision': [0.8907563025210085, 0.0], 'recall': [1.0, 0.0], 'f1-score': [0.9422222222222223, 0.0], 'support': [106.0, 0.0]}}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "{'Label 0': {'precision': [1.0, 0.0], 'recall': [0.9608540925266904, 0.0], 'f1-score': [0.9800362976406534, 0.0], 'support': [281.0, 0.0]}, 'Label 1': {'precision': [0.9051724137931034, 0.0], 'recall': [1.0, 0.0], 'f1-score': [0.9502262443438914, 0.0], 'support': [105.0, 0.0]}}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "{'Label 0': {'precision': [1.0, 0.0], 'recall': [0.9672727272727272, 1.1102230246251565e-16], 'f1-score': [0.9833641404805915, 0.0], 'support': [275.0, 0.0]}, 'Label 1': {'precision': [0.9181818181818182, 0.0], 'recall': [1.0, 0.0], 'f1-score': [0.957345971563981, 0.0], 'support': [101.0, 0.0]}}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "{'Label 0': {'precision': [1.0, 0.0], 'recall': [0.9741697416974169, 1.1102230246251565e-16], 'f1-score': [0.9869158878504672, 0.0], 'support': [271.0, 0.0]}, 'Label 1': {'precision': [0.9320388349514562, 1.1102230246251565e-16], 'recall': [1.0, 0.0], 'f1-score': [0.9648241206030151, 0.0], 'support': [96.0, 0.0]}}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "{'Label 0': {'precision': [1.0, 0.0], 'recall': [0.981203007518797, 0.0], 'f1-score': [0.9905123339658444, 0.0], 'support': [266.0, 0.0]}, 'Label 1': {'precision': [0.9489795918367347, 0.0], 'recall': [1.0, 0.0], 'f1-score': [0.9738219895287958, 0.0], 'support': [93.0, 0.0]}}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "{'Label 0': {'precision': [1.0, 0.0], 'recall': [0.98015873015873, 1.1102230246251565e-16], 'f1-score': [0.9899799599198396, 0.0], 'support': [252.0, 0.0]}, 'Label 1': {'precision': [0.9456521739130433, 1.1102230246251565e-16], 'recall': [1.0, 0.0], 'f1-score': [0.9720670391061452, 0.0], 'support': [87.0, 0.0]}}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "{'Label 0': {'precision': [0.9962732919254659, 0.0030428444009728975], 'recall': [0.9815950920245399, 0.0], 'f1-score': [0.9888774223139549, 0.0014979870765787088], 'support': [163.0, 0.0]}, 'Label 1': {'precision': [0.9602105263157894, 0.0002578410255561357], 'recall': [0.9917808219178081, 0.006710930802145721], 'f1-score': [0.975730092508616, 0.0033767680110923974], 'support': [73.0, 0.0]}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from xgboost import XGBClassifier,plot_importance\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def cuttinginput(df,alpha):\n",
    "    try:\n",
    "        df = df.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df_cols =df.columns.values\n",
    "    df_collist=['Case ID','Label_1','Label_0']\n",
    "    for k in df_cols:\n",
    "        if round(len(df[df[k]==1])/len(df),2) >alpha:\n",
    "            if k not in df_collist:\n",
    "                df_collist.append(k)\n",
    "\n",
    "    df = df.loc[:,df_collist]\n",
    "    return df, df_collist\n",
    "\n",
    "def rfclassifer():\n",
    "    alpha = 0\n",
    "    for prefixlength in range(5, 41, 5):\n",
    "        resultdict={}\n",
    "        resultdict['Label 0'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        resultdict['Label 1'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        for rndst in range(0,5):\n",
    "            \n",
    "            \n",
    "            wholefile = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\RIPPER\\prefix'+str(prefixlength)+'\\BPICinput_preprocessed.csv'\n",
    "            train = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\RIPPER\\prefix'+str(prefixlength)+'/train_rndst'+str(rndst)+'.csv'\n",
    "            test = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\RIPPER\\prefix'+str(prefixlength)+'/test_rndst'+str(rndst)+'.csv'\n",
    "            \n",
    "            wholefile,wh_collist = cuttinginput(pd.read_csv(wholefile),alpha)\n",
    "\n",
    "            \n",
    "            label = []\n",
    "            train = pd.read_csv(train)\n",
    "            test = pd.read_csv(test)\n",
    "            try:\n",
    "                train = train.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                test = test.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            train = train.loc[:,wh_collist]\n",
    "            test = test.loc[:,wh_collist]\n",
    "\n",
    "            for k in list(train['Label_1']):\n",
    "                if k==1:\n",
    "                    label.append(1)\n",
    "                else:\n",
    "                    label.append(0)\n",
    "            y_train = label\n",
    "            train = train.drop(['Label_1','Label_0','Case ID'],axis=1)\n",
    "            try:\n",
    "                test = test.drop(['Unnamed: 0'],axis=1)\n",
    "            except:\n",
    "                pass\n",
    "            x_train = train\n",
    "\n",
    "            label = []\n",
    "            for k in list(test['Label_1']):\n",
    "                if k==1:\n",
    "                    label.append(1)\n",
    "                else:\n",
    "                    label.append(0)\n",
    "\n",
    "            y_test = label\n",
    "            test = test.drop(['Label_1','Label_0','Case ID'],axis=1)\n",
    "            x_test = test\n",
    "            n_estimators = [100, 200, 300] # number of trees in the random forest\n",
    "            max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "            max_depth = [int(x) for x in np.linspace(10, 1001, num = 110)] # maximum number of levels allowed in each decision tree\n",
    "            min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "            min_samples_leaf = [1, 4, 7] # minimum sample number that can be stored in a leaf node\n",
    "            bootstrap = [True, False] # method used to sample data points\n",
    "            random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            randmrf = RandomForestClassifier()\n",
    "            from sklearn.model_selection import RandomizedSearchCV\n",
    "            rf_random = RandomizedSearchCV(estimator = randmrf,param_distributions = random_grid,\n",
    "               n_iter = 25, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
    "            rf_random.fit(x_train, y_train)\n",
    "            \n",
    "            rf=rf_random.best_estimator_\n",
    "            rf_pred = rf.predict(x_test)\n",
    "            result =classification_report(y_test,rf_pred,target_names=['Label 0','Label 1'],output_dict=True)\n",
    "            resultdict['Label 0']['precision'].append(result['Label 0']['precision'])\n",
    "            resultdict['Label 0']['recall'].append(result['Label 0']['recall'])\n",
    "            resultdict['Label 0']['f1-score'].append(result['Label 0']['f1-score'])\n",
    "            resultdict['Label 0']['support'].append(result['Label 0']['support'])\n",
    "            resultdict['Label 1']['precision'].append(result['Label 1']['precision'])\n",
    "            resultdict['Label 1']['recall'].append(result['Label 1']['recall'])\n",
    "            resultdict['Label 1']['f1-score'].append(result['Label 1']['f1-score'])\n",
    "            resultdict['Label 1']['support'].append(result['Label 1']['support'])\n",
    "\n",
    "        for pre in resultdict.keys():\n",
    "            for col in resultdict[pre].keys():\n",
    "                resultdict[pre][col] = [np.mean(resultdict[pre][col]),np.std(resultdict[pre][col])]\n",
    "\n",
    "\n",
    "        resultdir = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\prefix\\ruleresult\\randomforest'\n",
    "        try:    \n",
    "            os.makedirs(resultdir)\n",
    "        except:\n",
    "            pass\n",
    "        jsonname = resultdir+'/prefix'+str(prefixlength)+'result.json'\n",
    "        print(resultdict)\n",
    "        with open(jsonname ,'w') as f:\n",
    "            json.dump(resultdict,f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rfreader():\n",
    "    alpha = 0\n",
    "    for prefixlength in range(5, 41, 5):\n",
    "        # print(prefixlength)\n",
    "        resultdir = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\prefix\\withoutsparse_'+str(alpha)+'/'\n",
    "        jsonname = resultdir+'/prefix'+str(prefixlength)+'result.json'\n",
    "        \n",
    "        with open(jsonname ,'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(data['Label 1']['f1-score'][0])\n",
    "        # print(data['Label 1']['f1-score'][0])\n",
    "rfclassifer()\n",
    "# rfreader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiADROEdolFP"
   },
   "source": [
    "# xgb_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.1-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\dias\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dias\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix :5 Rndst :0\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[19:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prefix :10 Rndst :0\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[19:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prefix :15 Rndst :0\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[19:05:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prefix :20 Rndst :0\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[19:07:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prefix :25 Rndst :0\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[20:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prefix :30 Rndst :0\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[20:14:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prefix :35 Rndst :0\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[20:20:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prefix :40 Rndst :0\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[20:25:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier,plot_importance\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "# dataset = pd.read_csv('./bpic2015/ltl1/bpic2015_1/indexbase/prefix5/simple_timediscretize/ARMinput_preprocessed.csv')\n",
    "# label = []\n",
    "# for k in list(dataset['Label_1']):\n",
    "#     if k==1:\n",
    "#         label.append(1)\n",
    "#     else:\n",
    "#         label.append(0)\n",
    "# y = label\n",
    "# dataset = dataset.drop(['Label_1','Label_0','Case ID'],axis=1)\n",
    "\n",
    "# x_train,x_test,y_train,y_test = train_test_split(dataset,y,test_size=0.3,random_state = 0)\n",
    "\n",
    "\n",
    "# xgb = XGBClassifier(n_estimators = 500,learning_rate=0.1,max_depth=4)\n",
    "# xgb.fit(x_train,y_train)\n",
    "# xgb_pred = xgb.predict(x_test)\n",
    "# print(classification_report(y_test,xgb_pred))\n",
    "\n",
    "# fig,ax = plt.subplots()\n",
    "# plot_importance(xgb,ax=ax)\n",
    "# plt.show()\n",
    "\n",
    "def cuttinginput(df,alpha):\n",
    "    try:\n",
    "        df = df.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df_cols =df.columns.values\n",
    "    df_collist=['Case ID','Label_1','Label_0']\n",
    "    for k in df_cols:\n",
    "        if round(len(df[df[k]==1])/len(df),2) >alpha:\n",
    "            if k not in df_collist:\n",
    "                df_collist.append(k)\n",
    "\n",
    "    df = df.loc[:,df_collist]\n",
    "    return df, df_collist\n",
    "\n",
    "\n",
    "\n",
    "def xgboosting():\n",
    "    for prefixlength in range(5, 41, 5):\n",
    "        resultdict={}\n",
    "        resultdict['Label 0'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        resultdict['Label 1'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        for rndst in range(0, 1):\n",
    "            print('Prefix :%s Rndst :%s'%(prefixlength,rndst))\n",
    "            alpha = 0\n",
    "            wholefile = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/RIPPER/prefix'+str(prefixlength)+'/BPICinput_preprocessed.csv'\n",
    "            wholefile = pd.read_csv(wholefile)\n",
    "\n",
    "            wholefile,wh_collist = cuttinginput(wholefile,alpha)\n",
    "           \n",
    "            train ,test = train_test_split(wholefile,test_size=0.3)\n",
    "            label = []\n",
    "            try:\n",
    "                train = train.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                test = test.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            for k in list(train['Label_1']):\n",
    "                if k==1:\n",
    "                    label.append(1)\n",
    "                else:\n",
    "                    label.append(0)\n",
    "            y_train = label\n",
    "            train = train.drop(['Label_1','Label_0','Case ID'],axis=1)\n",
    "            try:\n",
    "                test = test.drop(['Unnamed: 0'],axis=1)\n",
    "            except:\n",
    "                pass\n",
    "            x_train = train\n",
    "\n",
    "            label = []\n",
    "            for k in list(test['Label_1']):\n",
    "                if k==1:\n",
    "                    label.append(1)\n",
    "                else:\n",
    "                    label.append(0)\n",
    "\n",
    "            y_test = label\n",
    "            test = test.drop(['Label_1','Label_0','Case ID'],axis=1)\n",
    "            x_test = test\n",
    "            \n",
    "            n_estimators = [100, 200, 300] # number of trees in the random forest\n",
    "            learning_rate=[0.1, 0.3, 0.5]\n",
    "            subsample=[0.3, 0.5, 0.7]\n",
    "            max_depth = [int(x) for x in np.linspace(10, 1001, num = 110)] # maximum number of levels allowed in each decision tree\n",
    "            colsample_bytree=[0.5, 0.6, 0.7]\n",
    "            min_child_weight=[1, 2, 3, 4]\n",
    "            random_grid = {'n_estimators': n_estimators, 'learning_rate':learning_rate, 'subsample':subsample, \n",
    "                           'max_depth': max_depth, 'colsample_bytree':  colsample_bytree, 'min_child_weight':min_child_weight}\n",
    "            \n",
    "            randxgb = XGBClassifier()\n",
    "            from sklearn.model_selection import RandomizedSearchCV\n",
    "            xgb_random = RandomizedSearchCV(estimator = randxgb, param_distributions = random_grid, cv=5, n_iter = 25, \n",
    "                                                              scoring = 'roc_auc', error_score = 0, verbose = 3, n_jobs = -1)\n",
    "            xgb_random.fit(x_train, y_train)\n",
    "\n",
    "            xgb=xgb_random.best_estimator_\n",
    "            xgb_pred = xgb.predict(x_test)\n",
    "            result =classification_report(y_test,xgb_pred,target_names=['Label 0','Label 1'],output_dict=True)\n",
    "            resultdict['Label 0']['precision'].append(result['Label 0']['precision'])\n",
    "            resultdict['Label 0']['recall'].append(result['Label 0']['recall'])\n",
    "            resultdict['Label 0']['f1-score'].append(result['Label 0']['f1-score'])\n",
    "            resultdict['Label 0']['support'].append(result['Label 0']['support'])\n",
    "            resultdict['Label 1']['precision'].append(result['Label 1']['precision'])\n",
    "            resultdict['Label 1']['recall'].append(result['Label 1']['recall'])\n",
    "            resultdict['Label 1']['f1-score'].append(result['Label 1']['f1-score'])\n",
    "            resultdict['Label 1']['support'].append(result['Label 1']['support'])\n",
    "\n",
    "        for pre in resultdict.keys():\n",
    "            for col in resultdict[pre].keys():\n",
    "                resultdict[pre][col] = [np.mean(resultdict[pre][col]),np.std(resultdict[pre][col])]\n",
    "                \n",
    "        resultdir = r'C:\\Users\\Dias\\Desktop\\data\\dataset\\bpic2015_3\\prefix\\ruleresult\\xgboost'\n",
    "        try:\n",
    "            os.makedirs(resultdir)\n",
    "        except:\n",
    "            pass\n",
    "        jsonname = resultdir+'/prefix'+str(prefixlength)+'result.json'\n",
    "        with open(jsonname ,'w') as f:\n",
    "            json.dump(resultdict,f)\n",
    "\n",
    "'''\n",
    "for prefixlength in range(2,10):\n",
    "    resultdict={}\n",
    "    resultdict['Label 0'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "    resultdict['Label 1'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "\n",
    "    alpha = 0.2\n",
    "    wholefile = './road traffic/rule1/indexbase/prefix'+str(prefixlength)+'/simple_timediscretize/ARMinput_preprocessed.csv'\n",
    "    wholefile = pd.read_csv(wholefile)\n",
    "\n",
    "    wholefile,wh_collist = cuttinginput(wholefile,alpha)\n",
    "    print('Prefix :%s '%(prefixlength), len(wh_collist))\n",
    "'''\n",
    "xgboosting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix :5 Support :0.9 Rndst :0\n",
      "448\n",
      "8\n",
      "Prefix :10 Support :0.9 Rndst :0\n",
      "902\n",
      "8\n",
      "Prefix :15 Support :0.9 Rndst :0\n",
      "1436\n",
      "8\n",
      "Prefix :20 Support :0.9 Rndst :0\n",
      "2114\n",
      "9\n",
      "Prefix :25 Support :0.9 Rndst :0\n",
      "2755\n",
      "9\n",
      "Prefix :30 Support :0.9 Rndst :0\n",
      "3445\n",
      "9\n",
      "Prefix :35 Support :0.9 Rndst :0\n",
      "4133\n",
      "9\n",
      "Prefix :40 Support :0.9 Rndst :0\n",
      "4495\n",
      "10\n",
      "Prefix :5 Support :0.9 Rndst :1\n",
      "448\n",
      "8\n",
      "Prefix :10 Support :0.9 Rndst :1\n",
      "902\n",
      "8\n",
      "Prefix :15 Support :0.9 Rndst :1\n",
      "1436\n",
      "8\n",
      "Prefix :20 Support :0.9 Rndst :1\n",
      "2114\n",
      "9\n",
      "Prefix :25 Support :0.9 Rndst :1\n",
      "2755\n",
      "9\n",
      "Prefix :30 Support :0.9 Rndst :1\n",
      "3445\n",
      "9\n",
      "Prefix :35 Support :0.9 Rndst :1\n",
      "4133\n",
      "9\n",
      "Prefix :40 Support :0.9 Rndst :1\n",
      "4495\n",
      "10\n",
      "Prefix :5 Support :0.9 Rndst :2\n",
      "448\n",
      "8\n",
      "Prefix :10 Support :0.9 Rndst :2\n",
      "902\n",
      "8\n",
      "Prefix :15 Support :0.9 Rndst :2\n",
      "1436\n",
      "8\n",
      "Prefix :20 Support :0.9 Rndst :2\n",
      "2114\n",
      "9\n",
      "Prefix :25 Support :0.9 Rndst :2\n",
      "2755\n",
      "9\n",
      "Prefix :30 Support :0.9 Rndst :2\n",
      "3445\n",
      "9\n",
      "Prefix :35 Support :0.9 Rndst :2\n",
      "4133\n",
      "9\n",
      "Prefix :40 Support :0.9 Rndst :2\n",
      "4495\n",
      "10\n",
      "Prefix :5 Support :0.9 Rndst :3\n",
      "448\n",
      "8\n",
      "Prefix :10 Support :0.9 Rndst :3\n",
      "902\n",
      "8\n",
      "Prefix :15 Support :0.9 Rndst :3\n",
      "1436\n",
      "8\n",
      "Prefix :20 Support :0.9 Rndst :3\n",
      "2114\n",
      "9\n",
      "Prefix :25 Support :0.9 Rndst :3\n",
      "2755\n",
      "9\n",
      "Prefix :30 Support :0.9 Rndst :3\n",
      "3445\n",
      "9\n",
      "Prefix :35 Support :0.9 Rndst :3\n",
      "4133\n",
      "9\n",
      "Prefix :40 Support :0.9 Rndst :3\n",
      "4495\n",
      "10\n",
      "Prefix :5 Support :0.9 Rndst :4\n",
      "448\n",
      "8\n",
      "Prefix :10 Support :0.9 Rndst :4\n",
      "902\n",
      "8\n",
      "Prefix :15 Support :0.9 Rndst :4\n",
      "1436\n",
      "8\n",
      "Prefix :20 Support :0.9 Rndst :4\n",
      "2114\n",
      "9\n",
      "Prefix :25 Support :0.9 Rndst :4\n",
      "2755\n",
      "9\n",
      "Prefix :30 Support :0.9 Rndst :4\n",
      "3445\n",
      "9\n",
      "Prefix :35 Support :0.9 Rndst :4\n",
      "4133\n",
      "9\n",
      "Prefix :40 Support :0.9 Rndst :4\n",
      "4495\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from mlxtend.frequent_patterns import fpgrowth,apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cuttinginput(df,alpha):\n",
    "    try:\n",
    "        df = df.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "    except:\n",
    "        pass\n",
    "    print(len(df.columns.values))\n",
    "    df_cols =df.columns.values\n",
    "    df_collist=['Case ID','Label_1','Label_0']\n",
    "    for k in df_cols:\n",
    "        if round(len(df[df[k]==1])/len(df),2) >alpha:\n",
    "            if k not in df_collist:\n",
    "                df_collist.append(k)\n",
    "\n",
    "    df = df.loc[:,df_collist]\n",
    "    print(len(df_collist))\n",
    "    return df, df_collist\n",
    "\n",
    "\n",
    "\n",
    "def bpic2012():\n",
    "    for rndst in [0,1,2,3,4]:\n",
    "        for length in range(5, 41, 5):\n",
    "            for support in [0.9]:\n",
    "                alpha=0.7\n",
    "\n",
    "                print('Prefix :%s Support :%s Rndst :%s'%(length,support,rndst))       \n",
    "                dir_path = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/RIPPER/prefix'+str(length)\n",
    "                filename = dir_path + '/train_rndst'+str(rndst)+'.csv'\n",
    "                wholefile = dir_path+'/BPICinput_preprocessed.csv'\n",
    "                wholefile,wh_collist = cuttinginput(pd.read_csv(wholefile),alpha)\n",
    "\n",
    "                df = pd.read_csv(filename)\n",
    "                try:\n",
    "                    df = df.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "                except:\n",
    "                    pass\n",
    "                threshold = 0.9\n",
    "                df =df.loc[:,wh_collist]\n",
    "                min_support = support\n",
    "                min_threshold = threshold\n",
    "                dir_path=dir_path+'/threshold'+str(threshold)+'/support_'+str(min_support)\n",
    "                try:\n",
    "                    os.makedirs(dir_path)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                df = df.drop(columns=['Case ID'],axis=1)\n",
    "\n",
    "                accepted = df[df['Label_1']==1]\n",
    "                refused = df[df['Label_0']==1]\n",
    "                '''\n",
    "                Accepted\n",
    "                '''\n",
    "                frequent_itemsets = apriori(accepted,min_support=min_support,use_colnames=True)\n",
    "                label1 = association_rules(frequent_itemsets,metric='confidence',min_threshold = min_threshold)\n",
    "                label1['consequents'] = [list(x) for x in list(label1['consequents'])]\n",
    "\n",
    "                labelin=[]\n",
    "                for pos,x in enumerate(list(label1['consequents'])):\n",
    "                    if 'Label_1' in x:\n",
    "                        labelin.append(pos)\n",
    "            \n",
    "                label1_name = dir_path+'/association_result_1_rnd'+str(rndst)+'.json'\n",
    "                label1 = label1.loc[labelin,:]#['antecedents','consequents']]\n",
    "                label1['antecedents'] = [list(x) for x in list(label1['antecedents'])] \n",
    "                label1.to_json(label1_name,orient='columns')\n",
    "                label1.to_csv(dir_path+'/label1result_rndst'+str(rndst)+'.csv',index=False)\n",
    "\n",
    "\n",
    "                \n",
    "                '''\n",
    "                Refused\n",
    "                '''\n",
    "                # print('Label 0!')\n",
    "                frequent_itemsets = apriori(refused,min_support=min_support,use_colnames=True)\n",
    "                label1 = association_rules(frequent_itemsets,metric='confidence',min_threshold = min_threshold)\n",
    "                label1['consequents'] = [list(x) for x in list(label1['consequents'])]\n",
    "\n",
    "                labelin=[]\n",
    "                for pos,x in enumerate(list(label1['consequents'])):\n",
    "                    if 'Label_0' in x:\n",
    "                        labelin.append(pos)\n",
    "\n",
    "                label1_name = dir_path+'/association_result_0_rnd'+str(rndst)+'.json'\n",
    "                label1 = label1.loc[labelin,:]#['antecedents','consequents']]\n",
    "                label1['antecedents'] = [list(x) for x in list(label1['antecedents'])]\n",
    "                label1.to_json(label1_name,orient='columns')\n",
    "                label1.to_csv(dir_path+'/label0result_rndst'+str(rndst)+'.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "bpic2012()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix : 5, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_5_label0_rnd_0.json\n",
      "Prefix : 10, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_10_label0_rnd_0.json\n",
      "Prefix : 15, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_15_label0_rnd_0.json\n",
      "Prefix : 20, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_20_label0_rnd_0.json\n",
      "Prefix : 25, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_25_label0_rnd_0.json\n",
      "Prefix : 30, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_30_label0_rnd_0.json\n",
      "Prefix : 35, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_35_label0_rnd_0.json\n",
      "Prefix : 40, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_40_label0_rnd_0.json\n",
      "Prefix : 5, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_5_label0_rnd_1.json\n",
      "Prefix : 10, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_10_label0_rnd_1.json\n",
      "Prefix : 15, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_15_label0_rnd_1.json\n",
      "Prefix : 20, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_20_label0_rnd_1.json\n",
      "Prefix : 25, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_25_label0_rnd_1.json\n",
      "Prefix : 30, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_30_label0_rnd_1.json\n",
      "Prefix : 35, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_35_label0_rnd_1.json\n",
      "Prefix : 40, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_40_label0_rnd_1.json\n",
      "Prefix : 5, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_5_label0_rnd_2.json\n",
      "Prefix : 10, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_10_label0_rnd_2.json\n",
      "Prefix : 15, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_15_label0_rnd_2.json\n",
      "Prefix : 20, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_20_label0_rnd_2.json\n",
      "Prefix : 25, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_25_label0_rnd_2.json\n",
      "Prefix : 30, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_30_label0_rnd_2.json\n",
      "Prefix : 35, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_35_label0_rnd_2.json\n",
      "Prefix : 40, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_40_label0_rnd_2.json\n",
      "Prefix : 5, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_5_label0_rnd_3.json\n",
      "Prefix : 10, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_10_label0_rnd_3.json\n",
      "Prefix : 15, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_15_label0_rnd_3.json\n",
      "Prefix : 20, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_20_label0_rnd_3.json\n",
      "Prefix : 25, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_25_label0_rnd_3.json\n",
      "Prefix : 30, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_30_label0_rnd_3.json\n",
      "Prefix : 35, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_35_label0_rnd_3.json\n",
      "Prefix : 40, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_40_label0_rnd_3.json\n",
      "Prefix : 5, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_5_label0_rnd_4.json\n",
      "Prefix : 10, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_10_label0_rnd_4.json\n",
      "Prefix : 15, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_15_label0_rnd_4.json\n",
      "Prefix : 20, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_20_label0_rnd_4.json\n",
      "Prefix : 25, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_25_label0_rnd_4.json\n",
      "Prefix : 30, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_30_label0_rnd_4.json\n",
      "Prefix : 35, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_35_label0_rnd_4.json\n",
      "Prefix : 40, Support :0.9\n",
      "C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold0.9/prefix_40_label0_rnd_4.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "#from playsound import playsound\n",
    "\n",
    "\n",
    "\n",
    "def way3():\n",
    "    for rndst in [0,1,2,3,4]:\n",
    "        for prefixlength in range(5,41, 5):\n",
    "            label1ruledict={}\n",
    "            label0ruledict={}\n",
    "            label0rule=set()\n",
    "            label1rule=set()\n",
    "            ruleset=set()\n",
    "            threshold=0.9\n",
    "            label1count = 0\n",
    "            label0count = 0\n",
    "            for support in [0.9]:\n",
    "                    print('Prefix : %s, Support :%s'%(prefixlength,support))\n",
    "                    dir_path = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/RIPPER/prefix'+str(prefixlength)\n",
    "                    dir_path=dir_path+'/threshold'+str(threshold)+'/support_'+str(support)\n",
    "                    label1 = dir_path+'/association_result_1_rnd'+str(rndst)+'.json'\n",
    "                    label0 = dir_path+'/association_result_0_rnd'+str(rndst)+'.json'\n",
    "                    label1ruledict[support] =set()\n",
    "                    label0ruledict[support] =set()\n",
    "\n",
    "                    with open(label1) as json_file:\n",
    "                        label1 = json.load(json_file)['antecedents']\n",
    "\n",
    "                    with open(label0) as json_file:\n",
    "                        label0 = json.load(json_file)['antecedents']\n",
    "\n",
    "                    for rule in label1.values():\n",
    "                        if len(rule) != 1:\n",
    "                            rule = sorted(rule)\n",
    "                            rule = '/'.join(rule)                               \n",
    "                        else:\n",
    "                            rule = rule[0]                        \n",
    "                        if rule not in label1rule:\n",
    "                            label1ruledict[support].add(rule)\n",
    "                            label1rule.add(rule)\n",
    "                        else:\n",
    "                            label1count +=1\n",
    "\n",
    "                    for rule in label0.values():\n",
    "                        if len(rule) !=1:\n",
    "                            rule = sorted(rule)\n",
    "                            rule = '/'.join(rule)                               \n",
    "                        else:\n",
    "                            rule = rule[0]\n",
    "                        \n",
    "                        if rule not in label0rule:\n",
    "                            label0ruledict[support].add(rule)\n",
    "                            label0rule.add(rule)\n",
    "                        else:\n",
    "                            label0count +=1\n",
    "            \n",
    "\n",
    "            for supp in label1ruledict.keys():\n",
    "                rules = list(label1ruledict[supp])\n",
    "                for value in rules:\n",
    "                    if value in label0rule:\n",
    "                        label1ruledict[supp].remove(value)\n",
    "\n",
    "            for supp in label0ruledict.keys():\n",
    "                rules = list(label0ruledict[supp])\n",
    "                for value in rules:\n",
    "                    if value in label1rule:\n",
    "                        label0ruledict[supp].remove(value)\n",
    "\n",
    "            for k in list(label1ruledict.keys()):\n",
    "                if len(label1ruledict[k])==0:\n",
    "                    del label1ruledict[k]\n",
    "                else:\n",
    "                    label1ruledict[k] = list(label1ruledict[k])\n",
    "\n",
    "            for k in list(label0ruledict.keys()):\n",
    "                if len(label0ruledict[k])==0:\n",
    "                    del label0ruledict[k]\n",
    "                else:\n",
    "                    label0ruledict[k] = list(label0ruledict[k])\n",
    "            \n",
    "            label0rulelist = []\n",
    "            label1rulelist = []\n",
    "            for k in label0ruledict.values():\n",
    "                label0rulelist +=k\n",
    "            \n",
    "            for k in label1ruledict.values():\n",
    "                label1rulelist +=k\n",
    "            \n",
    "            for s in label0rulelist:\n",
    "                if s in label1rulelist:\n",
    "                    print(s)     \n",
    "\n",
    "            ruleresult = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold'+str(threshold)\n",
    "            try:\n",
    "                os.makedirs(ruleresult)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            json_name = ruleresult+'/prefix_'+str(prefixlength)+'_label1_rnd_'+str(rndst)+'.json'\n",
    "            with open(json_name,'w') as json_file:\n",
    "                json.dump(label1ruledict,json_file)\n",
    "\n",
    "            json_name = ruleresult+'/prefix_'+str(prefixlength)+'_label0_rnd_'+str(rndst)+'.json'\n",
    "            print(json_name)\n",
    "            with open(json_name,'w') as json_file:\n",
    "                json.dump(label0ruledict,json_file)\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    way3()\n",
    "    #playsound('../Yattong+edited+version.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#from playsound import playsound\n",
    "\n",
    "for prefix in range(5,41, 5):\n",
    "    for rndst in [0,1,2,3,4]:\n",
    "        ruledict = {'Label_1':{},'Label_0':{}}\n",
    "        threshold = 0.9\n",
    "        label1 = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold'+str(threshold)+'/prefix_'+str(prefix)+'_label1_rnd_'+str(rndst)+'.json'\n",
    "        \n",
    "        with open(label1,'r') as f:\n",
    "            label1 = json.load(f)\n",
    "        \n",
    "        supportlevelist = sorted(list(label1.keys()),key=len)\n",
    "        label1rules = []\n",
    "        \n",
    "        for x in supportlevelist:\n",
    "            label1rules +=label1[x]\n",
    "            ruledict['Label_1'][x] = label1[x]\n",
    "\n",
    "        label0 = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold'+str(threshold)+'/prefix_'+str(prefix)+'_label0_rnd_'+str(rndst)+'.json'\n",
    "        with open(label0,'r') as f:\n",
    "            label0 = json.load(f)\n",
    "        \n",
    "        supportlevelist = sorted(list(label0.keys()),key=len)\n",
    "        label0rules = []\n",
    "        \n",
    "        for x in supportlevelist:\n",
    "            label0rules +=label0[x]\n",
    "            ruledict['Label_0'][x] = label0[x]\n",
    "\n",
    "        savefilename = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold'+str(threshold)+'/Rule_prefix'+str(prefix)+'_rnd'+str(rndst)+'.json'\n",
    "        with open(savefilename,'w') as f:\n",
    "            json.dump(ruledict,f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comporison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix :5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-257ac1f241c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    265\u001b[0m                     \u001b[1;31m#result = fourthmethod(testset,rules,score_thr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                     \u001b[1;31m#result3=thirdmethod(testset, rules, score_thr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m                     \u001b[0mresult5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfifthmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrules2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m                     \"\"\"\"\n\u001b[0;32m    269\u001b[0m                     \u001b[0mresultdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label 0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label 0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-257ac1f241c7>\u001b[0m in \u001b[0;36mfifthmethod\u001b[1;34m(testset, rules)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mpredict_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label 0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Label 1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1985\u001b[0m             )\n\u001b[0;32m   1986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1987\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1988\u001b[0m                 \u001b[1;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1989\u001b[0m                 \u001b[1;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "# from playsound import playsound\n",
    "\n",
    "def loadrule(prefix,rndst,threshold):\n",
    "    filename = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold'+str(threshold)+'/Rule_prefix'+str(prefix)+'_rnd'+str(rndst)+'.json'\n",
    "    with open(filename,'r') as f:\n",
    "        rules = json.load(f)\n",
    "    label1rulepre = rules['Label_1']\n",
    "    label0rulepre = rules['Label_0']\n",
    "\n",
    "    label1rule =[]\n",
    "    for key in label1rulepre.keys():\n",
    "        for rule in label1rulepre[key]:\n",
    "            label1rule.append(rule)\n",
    "    \n",
    "    label0rule =[]\n",
    "    for key in label0rulepre.keys():\n",
    "        for rule in label0rulepre[key]:\n",
    "            label0rule.append(rule)\n",
    "    rules = {'Label_1':label1rule,'Label_0':label0rule}\n",
    "    return rules\n",
    "\n",
    "def loadrule2(prefix,rndst,threshold):\n",
    "    \n",
    "    filename = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/threshold'+str(threshold)+'/Rule_prefix'+str(prefix)+'_rnd'+str(rndst)+'.json'\n",
    "    with open(filename,'r') as f:\n",
    "        rules = json.load(f)\n",
    "    return rules\n",
    "\n",
    "\n",
    "def thirdmethod(testset,rules,score_thr):\n",
    "    df = pd.read_csv(testset)\n",
    "    label1 = 'Label_1'\n",
    "    label0 = 'Label_0'\n",
    "    label1rules = rules[label1]\n",
    "    label0rules = rules[label0]\n",
    "    try:\n",
    "        df = df.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "    except:\n",
    "        pass\n",
    "    caseidlist = list(df['Case ID'])\n",
    "    label1list = list(df['Label_1'])\n",
    "    label0list = list(df['Label_0'])\n",
    "\n",
    "    y_true = {}\n",
    "    for pos,case in enumerate(caseidlist):\n",
    "        if label1list[pos] ==1:\n",
    "            y_true[case] = [1]\n",
    "        else:\n",
    "            y_true[case] = [0]\n",
    "\n",
    "    for pos,k in enumerate(label1rules):\n",
    "        label1rules[pos] = k.split('/')\n",
    "\n",
    "    for pos,k in enumerate(label0rules):\n",
    "        label0rules[pos] = k.split('/')\n",
    "\n",
    "    df = df.drop(columns=['Case ID'],axis=1)\n",
    "    cols = df.columns.values\n",
    "    colindexing={}\n",
    "    for c in cols:\n",
    "        for pos,indexing in enumerate(list(df.loc[:,c])):\n",
    "            if indexing ==1:\n",
    "                if caseidlist[pos] not in colindexing.keys():\n",
    "                    colindexing[caseidlist[pos]] = [c]\n",
    "                else:\n",
    "                    colindexing[caseidlist[pos]].append(c)\n",
    "    \n",
    "    satisfyingrule={} #key = caseid, item = list [0] = # of satisfying label0 rules [1] = # of satisfying label0 rules\n",
    "    for caseid in colindexing.keys():\n",
    "        satisfyingrule[caseid] = [0]\n",
    "        for rule in label0rules:\n",
    "            result = all(elem in colindexing[caseid] for elem in rule)\n",
    "            if result:\n",
    "                satisfyingrule[caseid][0] +=1/len(label0rules)\n",
    "    \n",
    "    for case in list(satisfyingrule.keys()):\n",
    "        if satisfyingrule[case][0]>=score_thr:\n",
    "            y_true[case].append(0)\n",
    "        else:\n",
    "            y_true[case].append(1)\n",
    "\n",
    "    true_y = list(pd.DataFrame(y_true).T[0])\n",
    "    predict_y = list(pd.DataFrame(y_true).T[1])\n",
    "\n",
    "    result = classification_report(true_y,predict_y,target_names=['Label 0','Label 1'],output_dict=True)\n",
    "    return result\n",
    "\n",
    "def fourthmethod(testset,rules,score_thr):\n",
    "    df = pd.read_csv(testset)\n",
    "    label1 = 'Label_1'\n",
    "    label0 = 'Label_0'\n",
    "    label1rules = rules[label1]\n",
    "    label0rules = rules[label0]\n",
    "    try:\n",
    "        df = df.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "    except:\n",
    "        pass\n",
    "    caseidlist = list(df['Case ID'])\n",
    "    label1list = list(df['Label_1'])\n",
    "    label0list = list(df['Label_0'])\n",
    "\n",
    "    y_true = {}\n",
    "    for pos,case in enumerate(caseidlist):\n",
    "        if label1list[pos] ==1:\n",
    "            y_true[case] = [1]\n",
    "        else:\n",
    "            y_true[case] = [0]\n",
    "\n",
    "    for pos,k in enumerate(label1rules):\n",
    "        label1rules[pos] = k.split('/')\n",
    "\n",
    "    for pos,k in enumerate(label0rules):\n",
    "        label0rules[pos] = k.split('/')\n",
    "\n",
    "    df = df.drop(columns=['Case ID'],axis=1)\n",
    "    cols = df.columns.values\n",
    "    colindexing={}\n",
    "    for c in cols:\n",
    "        for pos,indexing in enumerate(list(df.loc[:,c])):\n",
    "            if indexing ==1:\n",
    "                if caseidlist[pos] not in colindexing.keys():\n",
    "                    colindexing[caseidlist[pos]] = [c]\n",
    "                else:\n",
    "                    colindexing[caseidlist[pos]].append(c)\n",
    "    \n",
    "    satisfyingrule={} #key = caseid, item = list [0] = # of satisfying label0 rules [1] = # of satisfying label0 rules\n",
    "    for caseid in colindexing.keys():\n",
    "        satisfyingrule[caseid] = [0]\n",
    "        for rule in label1rules:\n",
    "            result = all(elem in colindexing[caseid] for elem in rule)\n",
    "            if result:\n",
    "                satisfyingrule[caseid][0] +=1/len(label1rules)\n",
    "    \n",
    "    for case in list(satisfyingrule.keys()):\n",
    "        if satisfyingrule[case][0]>=score_thr:\n",
    "            y_true[case].append(1)\n",
    "        else:\n",
    "            y_true[case].append(0)\n",
    "\n",
    "    true_y = list(pd.DataFrame(y_true).T[0])\n",
    "    predict_y = list(pd.DataFrame(y_true).T[1])\n",
    "\n",
    "    result = classification_report(true_y,predict_y,target_names=['Label 0','Label 1'],output_dict=True)\n",
    "    return result\n",
    "\n",
    "def fifthmethod(testset,rules): #Use loadrule2 function\n",
    "    df = pd.read_csv(testset)\n",
    "    label1 = 'Label_1'\n",
    "    label0 = 'Label_0'\n",
    "    label1rules = rules[label1]\n",
    "    label0rules = rules[label0]\n",
    "\n",
    "    if len(label1rules) ==0 and len(label0rules)==0:\n",
    "        result = {'Label 1':{'precision':0,'recall':0,'f1-score':0,'support':0},'Label 0':{'precision':0,'recall':0,'f1-score':0,'support':0}}\n",
    "        return result\n",
    "    try:\n",
    "        df = df.rename(columns={'Label_1.0':'Label_1','Label_0.0':'Label_0'})\n",
    "    except:\n",
    "        pass\n",
    "    caseidlist = list(df['Case ID'])\n",
    "    label1list = list(df['Label_1'])\n",
    "    label0list = list(df['Label_0'])\n",
    "\n",
    "    y_true = {}\n",
    "    for pos,case in enumerate(caseidlist):\n",
    "        if label1list[pos] ==1:\n",
    "            y_true[case] = [1]\n",
    "        else:\n",
    "            y_true[case] = [0]\n",
    "\n",
    "    for subrule in label1rules.values():\n",
    "        for pos,smallrule in enumerate(subrule):\n",
    "            subrule[pos] = smallrule.split('/')\n",
    "    \n",
    "    for subrule in label0rules.values():\n",
    "        for pos,smallrule in enumerate(subrule):\n",
    "            subrule[pos] = smallrule.split('/')\n",
    "    \n",
    "    label0ruleweighted = 0\n",
    "    label1ruleweighted = 0\n",
    "    for supplevel in label0rules.keys():\n",
    "        subrule = label0rules[supplevel]\n",
    "        label0ruleweighted += float(supplevel)*len(subrule)    \n",
    "    for supplevel in label1rules.keys():\n",
    "        subrule = label1rules[supplevel]\n",
    "        label1ruleweighted += float(supplevel)*len(subrule)\n",
    "\n",
    "    df = df.drop(columns=['Case ID'],axis=1)\n",
    "    cols = df.columns.values\n",
    "    colindexing={}\n",
    "    for c in cols:\n",
    "        for pos,indexing in enumerate(list(df.loc[:,c])):\n",
    "            if indexing ==1:\n",
    "                if caseidlist[pos] not in colindexing.keys():\n",
    "                    colindexing[caseidlist[pos]] = [c]\n",
    "                else:\n",
    "                    colindexing[caseidlist[pos]].append(c)\n",
    "    \n",
    "    satisfyingrule={} #key = caseid, item = list [0] = # of satisfying label0 rules [1] = # of satisfying label0 rules\n",
    "    for caseid in colindexing.keys():\n",
    "        satisfyingrule[caseid] = [0,0]\n",
    "        for supplevel in label0rules.keys():\n",
    "            subrule = label0rules[supplevel]\n",
    "            for smallrule in subrule:\n",
    "                result = all(elem in colindexing[caseid] for elem in smallrule)\n",
    "                if result:\n",
    "                    satisfyingrule[caseid][0] +=float(supplevel)/label0ruleweighted\n",
    "\n",
    "        for supplevel in label1rules.keys():\n",
    "            subrule = label1rules[supplevel]\n",
    "            for smallrule in subrule:\n",
    "                result = all(elem in colindexing[caseid] for elem in smallrule)\n",
    "                if result:\n",
    "                    satisfyingrule[caseid][1] +=float(supplevel)/label1ruleweighted\n",
    "    \n",
    "        if satisfyingrule[caseid][0] > satisfyingrule[caseid][1]:\n",
    "            y_true[caseid].append(0)\n",
    "        elif satisfyingrule[caseid][0] < satisfyingrule[caseid][1]:\n",
    "            y_true[caseid].append(1)\n",
    "        else:\n",
    "            del(y_true[caseid])\n",
    "\n",
    "    true_y = list(pd.DataFrame(y_true).T[0])\n",
    "    predict_y = list(pd.DataFrame(y_true).T[1])\n",
    "\n",
    "    result = classification_report(true_y,predict_y,target_names=['Label 0','Label 1'],output_dict=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    for prefix in range(5,41, 5):\n",
    "        print(\"Prefix :%s\"%(prefix))\n",
    "        resultdict={}\n",
    "        resultdict['Label 0'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        resultdict['Label 1'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        \n",
    "        resultdict3={}\n",
    "        resultdict3['Label 0'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        resultdict3['Label 1'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        \n",
    "        resultdict5={}\n",
    "        resultdict5['Label 0'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "        resultdict5['Label 1'] ={'precision':[],'recall':[],'f1-score':[],'support':[]}\n",
    "\n",
    "        for score_thr in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "            for rndst in [0,1,2,3,4]:\n",
    "                for threshold in [0.9]:\n",
    "                    testset = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/RIPPER/prefix'+str(prefix)+'/test_rndst'+str(rndst)+'.csv'\n",
    "                    #rules=loadrule(prefix,rndst,threshold)\n",
    "                    rules2=loadrule2(prefix, rndst, threshold)\n",
    "                    #result = fourthmethod(testset,rules,score_thr)\n",
    "                    #result3=thirdmethod(testset, rules, score_thr)\n",
    "                    result5=fifthmethod(testset, rules2)\n",
    "                    \"\"\"\"\n",
    "                    resultdict['Label 0']['precision'].append(result['Label 0']['precision'])\n",
    "                    resultdict['Label 0']['recall'].append(result['Label 0']['recall'])\n",
    "                    resultdict['Label 0']['f1-score'].append(result['Label 0']['f1-score'])\n",
    "                    resultdict['Label 0']['support'].append(result['Label 0']['support'])\n",
    "                    resultdict['Label 1']['precision'].append(result['Label 1']['precision'])\n",
    "                    resultdict['Label 1']['recall'].append(result['Label 1']['recall'])\n",
    "                    resultdict['Label 1']['f1-score'].append(result['Label 1']['f1-score'])\n",
    "                    resultdict['Label 1']['support'].append(result['Label 1']['support'])\n",
    "                    \n",
    "                    resultdict3['Label 0']['precision'].append(result3['Label 0']['precision'])\n",
    "                    resultdict3['Label 0']['recall'].append(result3['Label 0']['recall'])\n",
    "                    resultdict3['Label 0']['f1-score'].append(result3['Label 0']['f1-score'])\n",
    "                    resultdict3['Label 0']['support'].append(result3['Label 0']['support'])\n",
    "                    resultdict3['Label 1']['precision'].append(result3['Label 1']['precision'])\n",
    "                    resultdict3['Label 1']['recall'].append(result3['Label 1']['recall'])\n",
    "                    resultdict3['Label 1']['f1-score'].append(result3['Label 1']['f1-score'])\n",
    "                    resultdict3['Label 1']['support'].append(result3['Label 1']['support'])\n",
    "                    \"\"\"\n",
    "                    resultdict5['Label 0']['precision'].append(result5['Label 0']['precision'])\n",
    "                    resultdict5['Label 0']['recall'].append(result5['Label 0']['recall'])\n",
    "                    resultdict5['Label 0']['f1-score'].append(result5['Label 0']['f1-score'])\n",
    "                    resultdict5['Label 0']['support'].append(result5['Label 0']['support'])\n",
    "                    resultdict5['Label 1']['precision'].append(result5['Label 1']['precision'])\n",
    "                    resultdict5['Label 1']['recall'].append(result5['Label 1']['recall'])\n",
    "                    resultdict5['Label 1']['f1-score'].append(result5['Label 1']['f1-score'])\n",
    "                    resultdict5['Label 1']['support'].append(result5['Label 1']['support'])\n",
    "            \"\"\"\"        \n",
    "                   \n",
    "            for pre in resultdict.keys():\n",
    "                for col in resultdict[pre].keys():\n",
    "                    resultdict[pre][col] = [np.mean(resultdict[pre][col]),np.std(resultdict[pre][col])]\n",
    "            resultdir = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/fourthmethod/score_thr'+str(score_thr)\n",
    "            try:\n",
    "                os.makedirs(resultdir)\n",
    "            except:\n",
    "                pass\n",
    "            jsonname = resultdir+'/prefix'+str(prefix)+'result.json'\n",
    "            print(score_thr, rndst)\n",
    "            with open(jsonname ,'w') as f:\n",
    "                json.dump(resultdict,f)\n",
    "                \n",
    "            for pre in resultdict3.keys():\n",
    "                for col in resultdict3[pre].keys():\n",
    "                    resultdict3[pre][col] = [np.mean(resultdict3[pre][col]),np.std(resultdict3[pre][col])]\n",
    "            resultdir3 = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/thirdmethod/score_thr'+str(score_thr)\n",
    "            try:\n",
    "                os.makedirs(resultdir3)\n",
    "            except:\n",
    "                pass\n",
    "            jsonname3 = resultdir3+'/prefix'+str(prefix)+'result.json'\n",
    "            print(score_thr, rndst)\n",
    "            with open(jsonname3 ,'w') as f:\n",
    "                json.dump(resultdict3,f)\n",
    "            \"\"\"   \n",
    "            for pre in resultdict5.keys():\n",
    "                for col in resultdict5[pre].keys():\n",
    "                    resultdict5[pre][col] = [np.mean(resultdict5[pre][col]),np.std(resultdict5[pre][col])]\n",
    "            resultdir5 = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/ruleresult/way3/fifthmethod/score_thr'+str(score_thr)\n",
    "            try:\n",
    "                os.makedirs(resultdir5)\n",
    "            except:\n",
    "                pass\n",
    "            jsonname5 = resultdir5+'/prefix'+str(prefix)+'result.json'\n",
    "            print(score_thr, rndst)\n",
    "            with open(jsonname5 ,'w') as f:\n",
    "                json.dump(resultdict5,f)\n",
    "               \n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conviction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:00, 65191.24it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, 22919.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  5 Rnd 0\n",
      "7\n",
      "Prefix  5 Rnd 1\n",
      "7\n",
      "Prefix  5 Rnd 2\n",
      "7\n",
      "Prefix  5 Rnd 3\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "65it [00:00, 66495.06it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  5 Rnd 4\n",
      "7\n",
      "Prefix  10 Rnd 0\n",
      "7\n",
      "Prefix  10 Rnd 1\n",
      "7\n",
      "Prefix  10 Rnd 2\n",
      "7\n",
      "Prefix  10 Rnd 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "65it [00:00, 64634.84it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, 19042.24it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Prefix  10 Rnd 4\n",
      "7\n",
      "Prefix  15 Rnd 0\n",
      "7\n",
      "Prefix "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "66it [00:00, 66130.93it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15 Rnd 1\n",
      "7\n",
      "Prefix  15 Rnd 2\n",
      "7\n",
      "Prefix  15 Rnd 3\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, 19051.34it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, 19042.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  15 Rnd 4\n",
      "7\n",
      "Prefix  20 Rnd 0\n",
      "7\n",
      "Prefix  20 Rnd 1\n",
      "7\n",
      "Prefix  20 Rnd 2\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  20 Rnd 3\n",
      "7\n",
      "Prefix  20 Rnd 4\n",
      "7\n",
      "Prefix  25 Rnd 0\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, ?it/s]\n",
      "66it [00:00, 66115.13it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  25 Rnd 1\n",
      "7\n",
      "Prefix  25 Rnd 2\n",
      "7\n",
      "Prefix  25 Rnd 3\n",
      "7\n",
      "Prefix  25 Rnd 4\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:00, 1014007.56it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, 233016.89it/s]\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "66it [00:00, 97817.69it/s]\n",
      "19it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  30 Rnd 0\n",
      "7\n",
      "Prefix  30 Rnd 1\n",
      "7\n",
      "Prefix  30 Rnd 2\n",
      "7\n",
      "Prefix  30 Rnd 3\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "66it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  30 Rnd 4\n",
      "7\n",
      "Prefix  35 Rnd 0\n",
      "7\n",
      "Prefix  35 Rnd 1\n",
      "7\n",
      "Prefix  35 Rnd 2\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  35 Rnd 3\n",
      "7\n",
      "Prefix  35 Rnd 4\n",
      "7\n",
      "Prefix  40 Rnd 0\n",
      "7\n",
      "Prefix  40 Rnd 1\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]\n",
      "65it [00:00, ?it/s]\n",
      "19it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix  40 Rnd 2\n",
      "7\n",
      "Prefix  40 Rnd 3\n",
      "7\n",
      "Prefix  40 Rnd 4\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import ast\n",
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "#from playsound import playsound\n",
    "from tqdm import tqdm\n",
    "\n",
    "def ersecommonrule(both_label):\n",
    "    label0df = both_label[0]\n",
    "    label1df = both_label[1]\n",
    "    label0rule = []\n",
    "    label1rule = []\n",
    "\n",
    "    for x in label0df['antecedents']:\n",
    "        x = sorted(ast.literal_eval(x))\n",
    "        label0rule.append(str(x))\n",
    "\n",
    "    for x in label1df['antecedents']:\n",
    "        x = sorted(ast.literal_eval(x))\n",
    "        label1rule.append(str(x))\n",
    "    label0rules = frozenset(label0rule)\n",
    "    label1rules = frozenset(label1rule)\n",
    "    commonrule = label0rules.intersection(label1rules)\n",
    "    print(len(commonrule))\n",
    "    unqiuelabel0 = [pos for pos,x in tqdm(enumerate(label0rule)) if x not in commonrule]\n",
    "    unqiuelabel1 = [pos for pos,x in tqdm(enumerate(label1rule)) if x not in commonrule]\n",
    "    \n",
    "    return label0df.iloc[unqiuelabel0,:], label1df.iloc[unqiuelabel1,:]\n",
    "\n",
    "def summarizerule(ndf):\n",
    "    if len(ndf) ==0:\n",
    "        return {}\n",
    "    # ndf['conviction dist'] =abs(ndf['conviction'] - 1)\n",
    "    groups = ndf.groupby('antecedents')\n",
    "    rulebeforeclustering=[]\n",
    "    for case, group in groups:\n",
    "        group = group.sort_values(by='conviction',ascending=False)\n",
    "        group = group.reset_index(drop=True)\n",
    "        rulebeforeclustering.append(group.iloc[0,:])\n",
    "        \n",
    "    ndf = pd.DataFrame(rulebeforeclustering).reset_index(drop=True)\n",
    "    allelement = set()\n",
    "    for x in list(ndf['antecedents']):\n",
    "        x = ast.literal_eval(x)\n",
    "        for k in x:\n",
    "            allelement.add(k)\n",
    "    \n",
    "    for pos,x in enumerate(list(ndf['antecedents'])):\n",
    "        x = ast.literal_eval(x)\n",
    "        for k in allelement:\n",
    "            if k in x:\n",
    "                ndf.loc[pos,k] =1\n",
    "            else:\n",
    "                ndf.loc[pos,k] =0\n",
    "\n",
    "    try:\n",
    "        model = KMeans(n_clusters=20)\n",
    "        model.fit(ndf.loc[:,allelement])\n",
    "\n",
    "        y_predict = model.fit_predict(ndf.loc[:,allelement])\n",
    "\n",
    "        ndf['cluster'] = y_predict\n",
    "        groups = ndf.groupby('cluster')\n",
    "        topsupport = []\n",
    "        for case, group in groups:\n",
    "            group = group.sort_values(by='support',ascending=False)\n",
    "            group = group.reset_index(drop=True)\n",
    "            topsupport.append(group.iloc[0,:])\n",
    "        ndf = pd.DataFrame(topsupport)\n",
    "    except:\n",
    "        pass\n",
    "    ndf = ndf.reset_index(drop=True)\n",
    "    supportlist= []\n",
    "    for x in ndf['support']:\n",
    "        supportlist.append(int(x*10)/10)\n",
    "    ndf['support'] =supportlist\n",
    "    data ={}\n",
    "    for pos,x in enumerate(list(ndf['antecedents'])):\n",
    "        x = ast.literal_eval(x)\n",
    "        rule = '/'.join(x)\n",
    "        supp = ndf.loc[pos,'support']\n",
    "        if supp not in list(data.keys()):\n",
    "            data[ndf.loc[pos,'support']] = [rule]\n",
    "        else:\n",
    "            data[ndf.loc[pos,'support']].append(rule)\n",
    "    return data\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    for prefix in range(5,41,5):\n",
    "        for rndst in range(0,5):\n",
    "            label_ruledf = []\n",
    "            print('Prefix ', prefix, \"Rnd\", rndst)\n",
    "            for label in [0,1]:\n",
    "                data=[]\n",
    "                for supp in [0.9]:\n",
    "                    df =  pd.read_csv(r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3/RIPPER/prefix'+str(prefix)+'/threshold0.9/support_'+str(supp)+'/label'+str(label)+'result_rndst'+str(rndst)+'.csv')                    \n",
    "                    # if len(df) !=0:\n",
    "                    data.append(df)\n",
    "\n",
    "                ndf = pd.concat(data)\n",
    "                label_ruledf.append(ndf)\n",
    "            data={}\n",
    "            label0df, label1df = ersecommonrule(label_ruledf)\n",
    "            data['Label_0'] = summarizerule(label0df)\n",
    "            data['Label_1'] = summarizerule(label1df)\n",
    "            rulefilename = r'C:/Users/Dias/Desktop/data/dataset/bpic2015_3//ruleresult/way3/threshold0.9/Summarized_Rule_prefix'+str(prefix)+'_rnd'+str(rndst)+'.json'\n",
    "            with open(rulefilename,'w') as f:\n",
    "                json.dump(data,f)\n",
    "    #playsound('../Yattong+edited+version.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "BPIC2012_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
